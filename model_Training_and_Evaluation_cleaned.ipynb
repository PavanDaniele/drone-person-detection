{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavanDaniele/drone-person-detection/blob/main/model_Training_and_Evaluation_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZxG26MjG3e7"
      },
      "source": [
        "# Set up: mount drive + import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn4hsdQa0oyk"
      },
      "source": [
        "**Important Information:** We need to activate the GPU on Colab (_Runtime --> Change runtime type_). \\\n",
        "Every time you start a new session (or reopen the notebook after a few hours) check that the GPU is still active. If we are not using the GPU it can take up to tens of hours to train the models. \\\n",
        "_GPU T4 is the best choice._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bafrlWt-G9_y",
        "outputId": "c7ac14be-62d3-488a-c8f4-0eb5583fdb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Run this Every time you start a new session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # to mount google drive (to see/access it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZRM0tKnG-Oj",
        "outputId": "8eae1811-8df2-4320-af40-ab1ff41d8988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.170-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.170-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.170 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics # Installation of Ultralytics for YOLO models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iIi5eOj24kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7572d6ec-c72a-47c2-9cdc-8fae086c687e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO # Import of Ultralytics for YOLO models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "B7lwWkpiu0JY"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Import base for EfficientDet:\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision import transforms\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# from effdet.efficientdet import HeadNet\n",
        "# from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
        "# from effdet.bench import unwrap_bench\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import json\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlwU4zYYYxnX"
      },
      "source": [
        "# General Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOtSOJRWpnEx"
      },
      "source": [
        "### Backbone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNetjej6sKWr"
      },
      "source": [
        "In Computer Vision, a _Backbone_ is the part of a convolutional neural network responsible for extracting the main features from an image. \\\n",
        "It serves as the shared base upon which subsequent modules are built (such as heads for classification, object detection, segmentation, etc.).\n",
        "\n",
        "\\\n",
        "Each backbone has been pre-trained on specific datasets (e.g., ImageNet) using particular preprocessing steps, input dimensions, normalization, and augmentation techniques, which should ideally be replicated during fine-tuning to maintain compatibility and achieve optimal performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWlCNAmDfJPv"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0R1TXAeOOLn"
      },
      "source": [
        "To train a deep learning model, it is essential to properly handle data loading and preparation. This is the task of the _Data Loader_, a component responsible for:\n",
        "- Loading images and their corresponding annotations (e.g., .txt or .json) from the dataset.\n",
        "- Applying preprocessing operations, such as resizing, normalization, data augmentation, etc.\n",
        "- Organizing data into batches to feed the model during training.\n",
        "\n",
        "\\\n",
        "Considering the limited resources of my development environment, at first I decided to perform the image and annotation resizing in a separate phase (prior to training), in order to:\n",
        "- Reduce the workload of the data loader during fine-tuning;\n",
        "- Increase data loading and training speed;\n",
        "- Ensure consistency between images and annotations.\n",
        "\n",
        "But due to the different type of scaling technique, I want to try to fine-tuning the model without any pre-scaling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RCnQiNkOdt4"
      },
      "source": [
        "The other transformations, instead, are handled by the model-specific data loader, since each model uses different preprocessing and normalization techniques. \\\n",
        "Moreover, some models require specific transformations to achieve optimal performance, and the libraries that provide the models (e.g., Ultralytics for YOLO, torchvision for EfficientDet/SSD) already implement loaders that are properly configured and optimized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSgaMN1SZHeW"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCOR7b1PV1W"
      },
      "source": [
        "Image normalization consists in scaling pixel values from the range [0, 255] to a more suitable interval (e.g., [0, 1] or [-1, 1]), often based on the mean and standard deviation of the pre-training dataset, with the goal of:\n",
        "- Avoiding overly large values in the tensors;\n",
        "- Making the model more stable during training;\n",
        "- Speeding up convergence.\n",
        "\n",
        "\\\n",
        "Normalization helps maintain a consistent pixel range and distribution, which is essential for pre-trained models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tw6aba8f75J"
      },
      "source": [
        "### Data Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPcoqopoPxS3"
      },
      "source": [
        "Data augmentation consists of random transformations (e.g., rotations, flips, crops, brightness changes, etc.) applied during training. Their purpose is to:\n",
        "- Simulate new visual conditions;\n",
        "- Increase dataset variety;\n",
        "- Reduce overfitting by improving the model’s ability to generalize.\n",
        "\n",
        "\\\n",
        "In practice, the semantic content of the image doesn't change (e.g., a person remains a person), but its visual appearance is altered to help the model \"learn better.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2QIAGYbgIhJ"
      },
      "source": [
        "\n",
        "My goal is to evaluate the real-world performance of each model in its ideal scenario, in order to select the most suitable one for deployment on the Jetson Nano. \\\n",
        "For this reason, each model is trained using its native augmentations, meaning the ones that were designed and optimized as part of its original architecture. \\\n",
        "It wouldn’t make sense to disable them or enforce a uniform setup across models, because what we want to observe is the maximum potential of each model, working in the way it was designed to perform best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX7HKNc7udFy"
      },
      "source": [
        "# Fine-Tuning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdC8RvUw1F_9"
      },
      "source": [
        "### YOLOv8n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z51qZOzlxvca"
      },
      "source": [
        "First of all we need to save the dataset locally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfB0GzrFxu7o",
        "outputId": "217a0c47-0abe-4db1-9004-f29116dad0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy completed: True\n"
          ]
        }
      ],
      "source": [
        "src = '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n'\n",
        "dst = '/content/AERALIS_YOLOv8n_local'  # is now on the local VM, NOT on drive\n",
        "\n",
        "# If the destination folder already exists, I delete it\n",
        "if os.path.exists(dst):\n",
        "  shutil.rmtree(dst)\n",
        "\n",
        "# Recursive copy of ENTIRE folder (and subfolders)\n",
        "shutil.copytree(src, dst)\n",
        "print(\"Copy completed:\", os.path.exists(dst))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rf3uEUe0j7t"
      },
      "source": [
        "Let's check the total free space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Wf22_i0Rok",
        "outputId": "a10861a9-3942-405f-aef4-b2e1b765130a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   56G   58G  49% /\n"
          ]
        }
      ],
      "source": [
        "!df -h / # It shows the total, used and free space on the root (/) of the Colab VM.\n",
        "\n",
        "# Avail column: space still available for your files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTQQX_sw0fQb",
        "outputId": "1d972f7a-a19e-4f8c-f5df-308f0bbfbac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.6G\t/content/AERALIS_YOLOv8n_local\n"
          ]
        }
      ],
      "source": [
        "# Show space used by your local folder\n",
        "!du -sh /content/AERALIS_YOLOv8n_local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj3PMKWJ1Z3f",
        "outputId": "fc323f6a-38ea-4289-d622-d474efd37499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140K\t/content/.config\n",
            "du: cannot access '/content/drive/.Encrypted/.shortcut-targets-by-id/1LQbD7p_iS5KLqGNdfrYEvsAx0i_bgB0h/projectUPV': No such file or directory\n",
            "67G\t/content/drive\n",
            "6.6G\t/content/AERALIS_YOLOv8n_local\n",
            "31M\t/content/runs_finetune\n",
            "55M\t/content/sample_data\n",
            "74G\t/content/\n"
          ]
        }
      ],
      "source": [
        "# Show space occupied by various folders in /content/.\n",
        "!du -h --max-depth=1 /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtwQcmy01Odt"
      },
      "source": [
        "We want to create the data.yaml file, which YOLO uses to know:\n",
        "- the path to the training, validation, and test images\n",
        "- the number of classes (nc)\n",
        "- the names of the classes (names)\n",
        "\n",
        "\\\n",
        "This file is used by YOLO to locate the images and their annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6VlyhGe1N10",
        "outputId": "6131ad44-926c-484b-ff7c-f80f3280a0e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "176"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YAML dataset (edit routes)\n",
        "data_yaml = \"\"\"\n",
        "train: /content/AERALIS_YOLOv8n_local/train/images\n",
        "val:   /content/AERALIS_YOLOv8n_local/val/images\n",
        "test:  /content/AERALIS_YOLOv8n_local/test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['person']\n",
        "\"\"\"\n",
        "open('data.yaml', 'w').write(data_yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmvOfl4IslZw"
      },
      "source": [
        "Perfect, we have correctly written the data.yaml file for the AERALIS_YOLOv8n dataset. Let's continue with the loading of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6PJD4WHubXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b99366d-7c24-4f01-f48d-f5447f7cc2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 354MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Upload the pre-trained model we want to use as a starting point\n",
        "\n",
        "model_YOLOv8n = YOLO('yolov8n.pt') # it is the model that will be fine-tuned on the custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67c-lmU6sdXp"
      },
      "source": [
        "We have now downloaded the pre-trained model from the official Ultralytics repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0gsz0CG6PPi"
      },
      "source": [
        "The **Batch size** is the number of images processed simultaneously in each training step. With 4-8GB of RAM, a batch size of 8 (or even less) is recommended, so we'll start with that value and reduce it if necessary.\n",
        "\n",
        "**Early Stopping** is a technique that automatically stops the training process if the model stops improving after a certain number of epochs. This helps prevent overfitting and saves time.\n",
        "\n",
        "**Workers** are the parallel processes used to load and preprocess data while the model is training. However, due to our limited resources, we’ll start with 2 workers, and if data loading errors occur, we'll reduce this number to 1 or even 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYQFf9Vf8Jwf",
        "outputId": "0789e1fd-b512-4beb-c9b4-b72785a3c0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# To see the available GPU\n",
        "print(torch.cuda.is_available()) # True = you have GPU --> if False then use device='cpu'\n",
        "print(torch.cuda.device_count()) # Name of GPU\n",
        "\n",
        "# If True and at least 1, you can use device=0.\n",
        "# If you don't have GPU: use device='cpu' (much slower).\n",
        "# Locally (not Colab): check with nvidia-smi from terminal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmQfxSxns7I3"
      },
      "source": [
        "Now that we have confirmation that the GPU is active we can train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMKnsnJl3Ywr",
        "outputId": "c666aa22-e33d-4327-e9e4-67bec60500d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=person_yolov8n4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_finetune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs_finetune/person_yolov8n4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3514.4±245.8 MB/s, size: 2026.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/AERALIS_YOLOv8n_local/train/labels.cache... 2395 images, 388 backgrounds, 0 corrupt: 100%|██████████| 2395/2395 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 901.0±20.7 MB/s, size: 2606.8 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/AERALIS_YOLOv8n_local/val/labels.cache... 515 images, 75 backgrounds, 0 corrupt: 100%|██████████| 515/515 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs_finetune/person_yolov8n4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns_finetune/person_yolov8n4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      2.03G      2.025      1.712      1.023         61        640: 100%|██████████| 150/150 [01:09<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.728       0.54      0.593      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      2.03G       2.04      1.462      1.036         52        640: 100%|██████████| 150/150 [01:05<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.713      0.505      0.537      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      2.03G      2.064      1.333      1.051         50        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.713      0.506       0.56      0.226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100       2.1G      2.013      1.301      1.046         39        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.719      0.551      0.594       0.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100       2.1G      2.005      1.235       1.04         45        640: 100%|██████████| 150/150 [01:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.807      0.518      0.612      0.268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      2.12G      1.969      1.188      1.033         37        640: 100%|██████████| 150/150 [01:06<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.613       0.49      0.499       0.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      2.12G      1.943      1.184      1.027         47        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.728      0.567      0.613      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100      2.14G      1.924      1.141      1.013         39        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.74      0.536      0.613      0.263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      2.14G      1.878       1.11     0.9923         40        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.765      0.599       0.66      0.289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100      2.14G      1.859      1.072     0.9979         61        640: 100%|██████████| 150/150 [01:07<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.851      0.582       0.67      0.306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      2.14G      1.861      1.068      0.997         40        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.797      0.609      0.693      0.323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      2.14G      1.791      1.034     0.9833         42        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.794      0.613      0.673      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      2.14G      1.773     0.9961     0.9758         47        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.788      0.623      0.685      0.327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      2.14G      1.769     0.9976     0.9777         36        640: 100%|██████████| 150/150 [01:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.817      0.603       0.69      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      2.15G      1.774     0.9841     0.9741         61        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.775      0.632      0.693      0.326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      2.15G      1.775     0.9779     0.9722         41        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.808      0.642       0.71      0.338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      2.17G      1.736      0.957     0.9694         61        640: 100%|██████████| 150/150 [01:05<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.84       0.64      0.722      0.341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      2.17G      1.749     0.9632     0.9686         65        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.827      0.626      0.712      0.339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      2.19G      1.723     0.9329      0.961         66        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.815      0.643      0.713      0.344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      2.19G      1.689     0.9235     0.9546         29        640: 100%|██████████| 150/150 [01:07<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.842      0.661      0.732      0.354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      2.19G      1.698     0.9341     0.9538         65        640: 100%|██████████| 150/150 [01:06<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.839      0.647      0.739      0.356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      2.19G      1.696     0.9209     0.9524         39        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.846      0.648      0.741      0.373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      2.28G      1.663     0.9109     0.9496         42        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873      0.643      0.752      0.376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      2.28G      1.648     0.8686     0.9518         57        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.809      0.668      0.747      0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      2.28G      1.629     0.8655     0.9397         44        640: 100%|██████████| 150/150 [01:05<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.858      0.691       0.77      0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100      2.28G      1.636     0.8714     0.9447         65        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.869      0.682      0.779       0.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      2.28G      1.625     0.8701     0.9404         52        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.82      0.676      0.755      0.365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      2.28G      1.623     0.8511     0.9372         42        640: 100%|██████████| 150/150 [01:07<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.841      0.684      0.773      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      2.28G       1.61     0.8552     0.9404         55        640: 100%|██████████| 150/150 [01:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.846      0.689      0.768      0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      2.28G      1.597     0.8364     0.9339         36        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.859      0.693       0.77      0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      2.28G      1.578     0.8265     0.9351         49        640: 100%|██████████| 150/150 [01:07<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.851      0.689      0.774      0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      2.28G      1.584     0.8297     0.9363         56        640: 100%|██████████| 150/150 [01:05<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.854      0.684       0.77      0.398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100      2.28G      1.589     0.8483     0.9337         44        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.856       0.71      0.793      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      2.28G      1.543     0.8078     0.9247         55        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.827      0.699      0.777      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      2.28G      1.557     0.8229     0.9245         31        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.854      0.715       0.79      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      2.28G       1.56     0.8033     0.9244         32        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.861      0.722      0.802      0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      2.28G      1.536     0.7947     0.9257         47        640: 100%|██████████| 150/150 [01:07<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882        0.7      0.794       0.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      2.28G      1.515     0.7877     0.9102         47        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.845      0.721      0.797      0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100      2.28G      1.523     0.7687     0.9156         68        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.868       0.71      0.798      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      2.28G      1.519     0.7921     0.9201         42        640: 100%|██████████| 150/150 [01:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.875      0.684      0.785      0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      2.28G      1.497     0.7757     0.9225         40        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.851      0.719      0.801      0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      2.28G      1.496     0.7626     0.9123         52        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.87      0.728      0.809      0.422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      2.28G      1.511     0.7667     0.9127         44        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.852      0.726      0.804      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      2.28G      1.516     0.7719     0.9157        102        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.868      0.734      0.817       0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      2.28G      1.495     0.7586     0.9097         66        640: 100%|██████████| 150/150 [01:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.866      0.731      0.814      0.417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100      2.28G      1.482     0.7577     0.9089         31        640: 100%|██████████| 150/150 [01:05<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.868       0.75      0.823      0.425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      2.28G      1.476     0.7516     0.9117         41        640: 100%|██████████| 150/150 [01:06<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.871      0.734      0.812      0.422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      2.28G      1.466     0.7448     0.9066         40        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.854      0.732      0.803      0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      2.28G      1.463     0.7505     0.9063         34        640: 100%|██████████| 150/150 [01:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.875      0.742      0.823      0.436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      2.38G      1.447     0.7293     0.8971         24        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.872      0.726      0.817      0.427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      2.38G      1.421     0.7202     0.9023         59        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.84      0.724      0.806      0.425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      2.38G      1.444      0.722     0.9002         31        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.866      0.712      0.806      0.425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100      2.38G      1.442      0.726     0.8949         51        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.876      0.729      0.827      0.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      2.38G      1.444     0.7267     0.8971         50        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873      0.733       0.82      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100      2.38G      1.419     0.7161     0.8971         29        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.85      0.753      0.824      0.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      2.38G      1.413     0.7102     0.8993         44        640: 100%|██████████| 150/150 [01:06<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.87      0.746       0.83      0.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      2.38G      1.413     0.7024     0.9053         36        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.879      0.753      0.828      0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      2.38G      1.384     0.6933     0.8941         80        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.875      0.724      0.814      0.422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      2.38G      1.398     0.6965     0.8937         29        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.876      0.749      0.834       0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100      2.38G      1.376       0.69     0.8971         60        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.87      0.746      0.827      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      2.38G      1.382     0.6847     0.8938         41        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873      0.732       0.82      0.444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      2.38G       1.39     0.6894     0.8923         32        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.868      0.742      0.822      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/100      2.38G      1.362     0.6772     0.8889         64        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.859      0.728      0.812      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     64/100      2.38G      1.378     0.6752     0.8906         63        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873      0.731      0.825      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     65/100      2.38G      1.344     0.6669     0.8851         43        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.866      0.751      0.834      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     66/100      2.38G      1.349     0.6609     0.8864         72        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.856      0.756      0.828      0.451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     67/100      2.38G      1.333     0.6547     0.8763         56        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.889      0.746      0.837      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     68/100      2.48G      1.354     0.6614     0.8842         39        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.881       0.73      0.829      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     69/100      2.48G       1.33     0.6526      0.883         55        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.884      0.739      0.833      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     70/100      2.48G      1.318     0.6449     0.8754         28        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.861      0.762      0.836      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     71/100      2.48G      1.324     0.6467     0.8785         22        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.862      0.759      0.832      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     72/100      2.48G      1.321      0.648     0.8729         58        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.874      0.741      0.832      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     73/100      2.48G      1.308     0.6405     0.8755         50        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.871      0.754      0.835      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     74/100      2.48G      1.314     0.6406     0.8758         49        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.893       0.75      0.844      0.463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     75/100      2.48G      1.309     0.6383     0.8745         43        640: 100%|██████████| 150/150 [01:05<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.893      0.753      0.845      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     76/100      2.48G      1.285     0.6355      0.877         31        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882      0.762      0.841      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     77/100      2.48G      1.303     0.6355     0.8734         45        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.86      0.758      0.839      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     78/100      2.48G      1.302     0.6324     0.8725         29        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.745      0.834      0.456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     79/100      2.48G      1.273      0.617     0.8774         44        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.872      0.755      0.843      0.463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     80/100      2.48G      1.279      0.616     0.8718         42        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.884      0.754      0.843       0.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     81/100      2.48G      1.264     0.6098     0.8733         65        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.875      0.767      0.845       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     82/100      2.48G      1.257     0.6066     0.8662         49        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.86      0.782      0.849       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     83/100      2.48G      1.269     0.6173     0.8651         40        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.89      0.754       0.84      0.467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     84/100      2.48G      1.272     0.6106     0.8697         66        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.763      0.846      0.466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     85/100      2.48G      1.248     0.6054     0.8662         40        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.88      0.769      0.856      0.476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     86/100      2.48G      1.233     0.5921     0.8635         50        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.872      0.764      0.844      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     87/100      2.48G      1.258     0.6098     0.8646         43        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.876      0.769      0.855      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     88/100      2.48G      1.245     0.6047     0.8615         42        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.761      0.852      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     89/100      2.48G      1.241     0.6014     0.8658         43        640: 100%|██████████| 150/150 [01:06<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258        0.9      0.759      0.854      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     90/100      2.48G      1.227     0.5937     0.8615         28        640: 100%|██████████| 150/150 [01:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.902      0.756      0.856      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     91/100      2.48G      1.246     0.6033     0.8731         22        640: 100%|██████████| 150/150 [01:07<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:06<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.874      0.771      0.847      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     92/100      2.48G      1.227     0.5855     0.8642         36        640: 100%|██████████| 150/150 [01:04<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.762      0.851      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     93/100      2.48G        1.2      0.576     0.8624         23        640: 100%|██████████| 150/150 [01:04<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.852      0.787      0.853      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     94/100      2.48G      1.188     0.5708     0.8609         35        640: 100%|██████████| 150/150 [01:04<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.872      0.783      0.859      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     95/100      2.48G      1.199      0.571     0.8616         23        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.904      0.757      0.853      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     96/100      2.48G      1.192     0.5721     0.8664         18        640: 100%|██████████| 150/150 [01:05<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258        0.9      0.758      0.851      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     97/100      2.48G      1.173     0.5639      0.856         21        640: 100%|██████████| 150/150 [01:04<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.887       0.77      0.856      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     98/100      2.48G      1.161     0.5505     0.8515         32        640: 100%|██████████| 150/150 [01:04<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.905       0.77      0.861      0.483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     99/100      2.48G       1.16     0.5538     0.8518         29        640: 100%|██████████| 150/150 [01:05<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.908      0.761      0.855      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "    100/100      2.48G      1.154     0.5461     0.8617         15        640: 100%|██████████| 150/150 [01:04<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.896      0.769      0.857      0.481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "100 epochs completed in 2.009 hours.\n",
            "Optimizer stripped from runs_finetune/person_yolov8n4/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs_finetune/person_yolov8n4/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs_finetune/person_yolov8n4/weights/best.pt...\n",
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.905      0.771      0.861      0.482\n",
            "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns_finetune/person_yolov8n4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Fine‑tuning\n",
        "results_YOLOv8n = model_YOLOv8n.train(\n",
        "  data='data.yaml', # use the newly created yaml file\n",
        "  epochs=100, # Maximum number of training epochs\n",
        "  imgsz=640, # Image input size (recommended for YOLO).\n",
        "  batch=16,  # Batch size\n",
        "  patience=20, # Early stopping if the metrics do not improve for 20 epochs\n",
        "  workers=2, # Number of workers for the dataloader\n",
        "  device=0, # Use GPU 0 (or put 'cpu' if you don't have GPU)\n",
        "  # device='cpu',\n",
        "  project='runs_finetune', # Folder where it will save the results of the experiments (the folder will be created automatically)\n",
        "  name='person_yolov8n' # Subfolder/name specific to our experiment\n",
        ")\n",
        "\n",
        "# results -->  will contain metrics, logs, and the path of the best weights found during the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fyPjFuZeghX"
      },
      "source": [
        "We now want to evaluate the trained model using the Test set defined in data.yaml. \\\n",
        "YOLO does not compute standard accuracy, because in object detection True Negatives (TN) are not counted. Therefore, traditional accuracy is not applicable or useful.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYLO2bxBfHoI"
      },
      "source": [
        "So, we will compute:\n",
        "- **Precision**: how correct your detected positives are\n",
        "- **Recall**: how many of the real objects you detected\n",
        "- **mAP50**: mean Average Precision with IoU ≥ 0.5 (how accurate the predictions are)\n",
        "- **mAP50-95**: average over various IoU thresholds, a more strict metric\n",
        "- **F1_score**: combination of precision and recall (you can compute it as: 2 * (P * R) / (P + R))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YAML dataset (edit routes)\n",
        "data_yaml_yolov8n = \"\"\"\n",
        "train: /content/AERALIS_YOLOv8n_local/train/images\n",
        "val:   /content/AERALIS_YOLOv8n_local/val/images\n",
        "test:  /content/AERALIS_YOLOv8n_local/test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['person']\n",
        "\"\"\"\n",
        "\n",
        "with open('data.yaml', 'w') as f:\n",
        "  f.write(data_yaml_yolov8n)"
      ],
      "metadata": {
        "id": "X3QY6mnZLXvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWuTdRMH3Yt7",
        "outputId": "1ed8fb4e-4747-487a-a221-9bcaa505ba62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 133MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3446.6±1599.2 MB/s, size: 1774.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/AERALIS_YOLOv8n_local/test/labels... 516 images, 93 backgrounds, 0 corrupt: 100%|██████████| 516/516 [00:00<00:00, 1388.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/AERALIS_YOLOv8n_local/test/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:07<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        516       1271      0.513      0.219      0.275      0.126\n",
            "                person        423       1271      0.513      0.219      0.275      0.126\n",
            "Speed: 0.4ms preprocess, 1.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "Test metrics: ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e00c8194510>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,\n",
            "            0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,\n",
            "            0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,\n",
            "            0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.93443,     0.92701,     0.92701,\n",
            "            0.92701,     0.92701,     0.92701,     0.92701,     0.92701,     0.92701,     0.92701,     0.92701,     0.92143,     0.92143,     0.91549,     0.91096,     0.91096,     0.90728,     0.90728,     0.90728,     0.90196,     0.89697,     0.89697,     0.89697,     0.89697,     0.89697,     0.89697,\n",
            "            0.89697,     0.89697,     0.88166,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86957,     0.86559,     0.85789,     0.85789,     0.85492,     0.85128,     0.84848,     0.84848,     0.84729,     0.84729,     0.84729,     0.84286,     0.84286,\n",
            "            0.84286,     0.84286,     0.83256,     0.83105,     0.83105,     0.83105,     0.82589,     0.82589,     0.81938,     0.81034,      0.7875,     0.76923,     0.76707,     0.75097,      0.7433,     0.73864,     0.73684,     0.73333,     0.72894,     0.72727,     0.71631,     0.70732,     0.70103,\n",
            "             0.6873,      0.6873,      0.6873,      0.6873,      0.6873,     0.67619,     0.67619,     0.67508,     0.66873,     0.65758,     0.65663,     0.64793,     0.64431,     0.64162,      0.6408,     0.63277,     0.61853,     0.61853,     0.61789,     0.60686,      0.6063,     0.60363,     0.60363,\n",
            "            0.59796,     0.59698,     0.59698,     0.58477,     0.58394,     0.58213,     0.58034,     0.56876,     0.56081,     0.56081,     0.56081,     0.56081,     0.56054,     0.56027,     0.55315,     0.55315,     0.55315,     0.54701,     0.54681,     0.54603,     0.54603,     0.54603,     0.54564,\n",
            "            0.54098,     0.54065,     0.54065,     0.53815,       0.538,     0.53785,     0.52724,      0.5249,      0.5249,     0.52281,     0.51776,     0.51481,     0.51099,     0.49911,     0.49561,     0.49306,     0.49306,      0.4906,      0.4906,     0.48735,     0.48735,     0.48581,      0.4851,\n",
            "             0.4851,     0.47805,     0.44595,     0.44595,     0.44544,     0.44296,     0.43814,     0.43786,     0.43786,      0.4314,     0.43099,     0.42112,     0.41848,     0.41835,     0.41689,     0.41656,     0.41402,     0.41393,     0.40669,     0.40561,     0.40431,     0.39702,      0.3901,\n",
            "             0.3901,     0.38371,     0.38371,     0.38353,      0.3829,     0.38211,     0.37614,     0.37614,     0.37124,     0.36947,      0.3658,      0.3658,      0.3658,      0.3653,      0.3652,     0.36422,     0.36412,     0.35773,     0.35773,     0.35773,     0.35729,     0.35576,     0.35247,\n",
            "            0.35015,     0.35015,     0.35015,     0.34838,     0.34426,     0.34324,     0.34223,     0.33897,     0.33612,     0.33212,     0.33212,     0.32885,     0.32885,       0.328,       0.328,     0.32601,     0.32546,     0.32325,     0.32164,     0.32164,     0.32003,      0.3198,     0.31693,\n",
            "             0.3154,     0.31466,     0.31393,      0.3123,      0.3123,     0.30985,      0.3035,      0.3035,     0.30287,     0.30247,     0.29381,     0.29346,     0.28936,     0.28936,     0.28788,     0.28674,     0.28653,     0.28411,     0.28411,     0.28243,     0.28194,     0.27755,     0.27467,\n",
            "            0.27467,     0.27467,      0.2746,     0.27454,     0.27018,      0.2695,      0.2695,      0.2694,      0.2694,     0.26857,     0.26857,     0.26696,     0.26696,     0.26621,     0.26469,     0.26433,     0.26201,     0.25915,     0.25635,     0.25635,     0.25318,     0.25318,     0.25318,\n",
            "            0.25303,     0.25243,     0.25213,     0.25213,     0.25028,      0.2493,     0.24861,     0.24861,     0.24685,     0.24658,     0.24306,     0.24306,     0.24306,     0.24206,     0.24206,     0.23956,     0.23687,     0.23449,     0.23239,     0.22925,     0.22906,     0.22821,     0.22736,\n",
            "            0.22537,     0.22402,     0.22233,     0.22233,     0.22233,     0.22186,      0.2214,     0.21848,     0.21848,     0.21848,     0.21562,     0.21562,     0.21562,     0.21562,     0.21156,     0.20722,     0.20434,     0.20434,     0.20355,     0.20355,     0.20311,     0.20311,     0.19936,\n",
            "            0.19928,     0.19928,     0.19673,     0.19673,     0.19673,     0.19673,     0.19643,     0.19628,     0.19622,     0.19622,     0.19489,     0.19306,     0.19163,     0.19094,     0.19049,     0.19049,     0.18974,     0.18759,     0.18687,     0.18676,     0.18612,     0.18242,     0.18216,\n",
            "            0.18216,     0.18216,     0.17861,     0.17861,     0.17858,     0.17647,      0.1757,     0.17516,     0.17473,     0.17472,     0.17297,     0.17147,     0.17098,     0.16795,     0.16667,     0.16636,     0.16141,     0.16128,     0.16101,     0.16013,     0.15997,      0.1599,      0.1599,\n",
            "            0.15982,     0.15643,     0.15615,     0.15242,     0.15059,     0.15058,        0.15,     0.14931,     0.14773,     0.14315,     0.14207,     0.14161,     0.14064,     0.14013,     0.13544,     0.13361,     0.13298,     0.13251,     0.13058,     0.12987,     0.12987,     0.12987,      0.1296,\n",
            "            0.12842,     0.12697,     0.12548,     0.12243,     0.12236,     0.12236,     0.12194,      0.1206,      0.1206,     0.11803,     0.11703,     0.11664,     0.11538,      0.1148,     0.11383,      0.1121,      0.1121,     0.11079,     0.10926,      0.1086,     0.10742,     0.10718,     0.10718,\n",
            "            0.10718,     0.10641,     0.10635,     0.10598,     0.10553,     0.10495,     0.10259,     0.10228,     0.10071,     0.10071,     0.10013,    0.099931,    0.099733,    0.099536,    0.099338,     0.09914,    0.098942,    0.098744,    0.098546,    0.098348,     0.09815,    0.097952,    0.097755,\n",
            "           0.097557,    0.097359,    0.097161,    0.096963,    0.096765,    0.096567,    0.096369,    0.096171,    0.095974,    0.095776,    0.095578,     0.09538,    0.095182,    0.094984,    0.094786,    0.094588,    0.094391,    0.094193,    0.093995,    0.093797,    0.093599,    0.093401,    0.093203,\n",
            "           0.093005,    0.092807,     0.09261,    0.092412,    0.092214,    0.092016,    0.091818,     0.09162,    0.091422,    0.091224,    0.091027,    0.090829,    0.090631,    0.090433,    0.090235,    0.090037,    0.089839,    0.089641,    0.089443,    0.089246,    0.089048,     0.08885,    0.088652,\n",
            "           0.088454,    0.088256,    0.088058,     0.08786,    0.087662,    0.087465,    0.087267,    0.087069,    0.086871,    0.086673,    0.086475,    0.086277,    0.086079,    0.085882,    0.085684,    0.085486,    0.085288,     0.08509,    0.084892,    0.084694,    0.084496,    0.084298,    0.084101,\n",
            "           0.083903,    0.083705,    0.083507,    0.083309,    0.083111,    0.082913,    0.082715,    0.082518,     0.08232,    0.082122,    0.081924,    0.081726,    0.081528,     0.08133,    0.081132,    0.080934,    0.080737,    0.080539,    0.080341,    0.080143,    0.079945,    0.079747,    0.079549,\n",
            "           0.079351,    0.079153,    0.078956,    0.078758,     0.07856,    0.078362,    0.078164,    0.077966,    0.077768,     0.07757,    0.077373,    0.077175,    0.076977,    0.076779,    0.076581,    0.076383,    0.076185,    0.075987,    0.075789,    0.075592,    0.075394,    0.075196,    0.074998,\n",
            "             0.0748,    0.074602,    0.074404,    0.074206,    0.074009,    0.073811,    0.073613,    0.073415,    0.073217,    0.073019,    0.072821,    0.072623,    0.072425,    0.072228,     0.07203,    0.071832,    0.071634,    0.071436,    0.071238,     0.07104,    0.070842,    0.070644,    0.070447,\n",
            "           0.070249,    0.070051,    0.069853,    0.069655,    0.069457,    0.069259,    0.069061,    0.068864,    0.068666,    0.068468,     0.06827,    0.068072,    0.067874,    0.067676,    0.067478,     0.06728,    0.067083,    0.066885,    0.066687,    0.066489,    0.066291,    0.066093,    0.065895,\n",
            "           0.065697,      0.0655,    0.065302,    0.065104,    0.064906,    0.064708,     0.06451,    0.064312,    0.064114,    0.063916,    0.063719,    0.063521,    0.063323,    0.063125,    0.062927,    0.062729,    0.062531,    0.062333,    0.062135,    0.061938,     0.06174,    0.061542,    0.061344,\n",
            "           0.061146,    0.060948,     0.06075,    0.060552,    0.060355,    0.060157,    0.059959,    0.059761,    0.059563,    0.059365,    0.059167,    0.058969,    0.058771,    0.058574,    0.058376,    0.058178,     0.05798,    0.057782,    0.057584,    0.057386,    0.057188,    0.056991,    0.056793,\n",
            "           0.056595,    0.056397,    0.056199,    0.056001,    0.055803,    0.055605,    0.055407,     0.05521,    0.055012,    0.054814,    0.054616,    0.054418,     0.05422,    0.054022,    0.053824,    0.053626,    0.053429,    0.053231,    0.053033,    0.052835,    0.052637,    0.052439,    0.052241,\n",
            "           0.052043,    0.051846,    0.051648,     0.05145,    0.051252,    0.051054,    0.050856,    0.050658,     0.05046,    0.050262,    0.050065,    0.049867,    0.049669,    0.049471,    0.049273,    0.049075,    0.048877,    0.048679,    0.048482,    0.048284,    0.048086,    0.047888,     0.04769,\n",
            "           0.047492,    0.047294,    0.047096,    0.046898,    0.046701,    0.046503,    0.046305,    0.046107,    0.045909,    0.045711,    0.045513,    0.045315,    0.045117,     0.04492,    0.044722,    0.044524,    0.044326,    0.044128,     0.04393,    0.043732,    0.043534,    0.043337,    0.043139,\n",
            "           0.042941,    0.042743,    0.042545,    0.042347,    0.042149,    0.041951,    0.041753,    0.041556,    0.041358,     0.04116,    0.040962,    0.040764,    0.040566,    0.040368,     0.04017,    0.039973,    0.039775,    0.039577,    0.039379,    0.039181,    0.038983,    0.038785,    0.038587,\n",
            "           0.038389,    0.038192,    0.037994,    0.037796,    0.037598,      0.0374,    0.037202,    0.037004,    0.036806,    0.036608,    0.036411,    0.036213,    0.036015,    0.035817,    0.035619,    0.035421,    0.035223,    0.035025,    0.034828,     0.03463,    0.034432,    0.034234,    0.034036,\n",
            "           0.033838,     0.03364,    0.033442,    0.033244,    0.033047,    0.032849,    0.032651,    0.032453,    0.032255,    0.032057,    0.031859,    0.031661,    0.031464,    0.031266,    0.031068,     0.03087,    0.030672,    0.030474,    0.030276,    0.030078,     0.02988,    0.029683,    0.029485,\n",
            "           0.029287,    0.029089,    0.028891,    0.028693,    0.028495,    0.028297,    0.028099,    0.027902,    0.027704,    0.027506,    0.027308,     0.02711,    0.026912,    0.026714,    0.026516,    0.026319,    0.026121,    0.025923,    0.025725,    0.025527,    0.025329,    0.025131,    0.024933,\n",
            "           0.024735,    0.024538,     0.02434,    0.024142,    0.023944,    0.023746,    0.023548,     0.02335,    0.023152,    0.022955,    0.022757,    0.022559,    0.022361,    0.022163,    0.021965,    0.021767,    0.021569,    0.021371,    0.021174,    0.020976,    0.020778,     0.02058,    0.020382,\n",
            "           0.020184,    0.019986,    0.019788,     0.01959,    0.019393,    0.019195,    0.018997,    0.018799,    0.018601,    0.018403,    0.018205,    0.018007,     0.01781,    0.017612,    0.017414,    0.017216,    0.017018,     0.01682,    0.016622,    0.016424,    0.016226,    0.016029,    0.015831,\n",
            "           0.015633,    0.015435,    0.015237,    0.015039,    0.014841,    0.014643,    0.014446,    0.014248,     0.01405,    0.013852,    0.013654,    0.013456,    0.013258,     0.01306,    0.012862,    0.012665,    0.012467,    0.012269,    0.012071,    0.011873,    0.011675,    0.011477,    0.011279,\n",
            "           0.011081,    0.010884,    0.010686,    0.010488,     0.01029,    0.010092,   0.0098942,   0.0096963,   0.0094984,   0.0093005,   0.0091027,   0.0089048,   0.0087069,    0.008509,   0.0083111,   0.0081132,   0.0079153,   0.0077175,   0.0075196,   0.0073217,   0.0071238,   0.0069259,    0.006728,\n",
            "          0.0065302,   0.0063323,   0.0061344,   0.0059365,   0.0057386,   0.0055407,   0.0053429,    0.005145,   0.0049471,   0.0047492,   0.0045513,   0.0043534,   0.0041556,   0.0039577,   0.0037598,   0.0035619,    0.003364,   0.0031661,   0.0029683,   0.0027704,   0.0025725,   0.0023746,   0.0021767,\n",
            "          0.0019788,    0.001781,   0.0015831,   0.0013852,   0.0011873,  0.00098942,  0.00079153,  0.00059365,  0.00039577,  0.00019788,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16669,     0.16676,     0.21163,     0.23983,     0.25784,     0.26617,     0.27701,     0.28351,     0.28942,     0.29138,     0.29668,     0.29727,     0.29911,     0.29944,     0.30484,     0.30711,     0.30741,     0.30802,      0.3073,     0.30715,     0.30921,     0.30996,     0.30986,\n",
            "            0.30857,     0.30828,     0.30659,     0.30695,     0.30709,     0.30765,     0.30614,      0.3056,     0.30736,     0.30885,     0.30876,     0.30827,     0.30695,     0.30776,     0.30769,     0.30838,     0.30713,     0.30706,     0.30628,     0.30742,     0.30772,     0.30962,     0.31117,\n",
            "            0.31193,      0.3109,     0.30977,      0.3091,     0.30723,     0.30629,     0.30481,     0.30549,     0.30508,     0.30654,     0.30661,     0.30699,     0.30656,     0.30555,     0.30548,     0.30339,     0.30314,     0.30379,     0.30418,     0.30379,     0.30181,     0.30157,     0.29998,\n",
            "            0.29934,     0.29945,     0.29833,     0.29568,     0.29472,     0.29372,     0.29436,     0.29244,     0.29146,     0.29196,     0.28964,     0.28773,     0.28666,     0.28654,      0.2861,     0.28678,       0.287,     0.28666,     0.28574,     0.28592,     0.28515,     0.28356,     0.28307,\n",
            "            0.28366,     0.28399,     0.28222,     0.28157,     0.28099,     0.27934,     0.27815,      0.2779,     0.27802,     0.27835,     0.27769,     0.27542,     0.27412,     0.27434,      0.2745,     0.27501,     0.27531,     0.27511,      0.2752,     0.27494,     0.27455,     0.27362,      0.2735,\n",
            "            0.27184,     0.27198,     0.27196,     0.27163,     0.27166,     0.27006,     0.27055,     0.27078,     0.27014,     0.27021,     0.27005,     0.26926,     0.26936,     0.26942,     0.26948,     0.26843,     0.26799,     0.26655,     0.26712,     0.26618,     0.26424,     0.26257,      0.2603,\n",
            "            0.26021,     0.26041,     0.26053,     0.26111,     0.26022,     0.26055,     0.25993,     0.25965,     0.25972,      0.2598,     0.25973,     0.25825,     0.25831,     0.25838,     0.25846,     0.25854,     0.25872,     0.25766,     0.25669,     0.25681,     0.25692,     0.25676,     0.25632,\n",
            "            0.25589,      0.2549,     0.25406,     0.25338,     0.25313,     0.25304,      0.2523,      0.2524,     0.25215,     0.25122,     0.25078,     0.25034,     0.25044,     0.25052,     0.25056,      0.2506,     0.25064,     0.25084,     0.25088,     0.25091,     0.25095,     0.25115,     0.25023,\n",
            "             0.2503,     0.24922,     0.24944,     0.24969,     0.24998,     0.25004,     0.25008,     0.25012,     0.25016,     0.24975,     0.24925,     0.24907,     0.24922,     0.24937,     0.24943,     0.24949,     0.24955,     0.24961,     0.24968,     0.24981,     0.25009,     0.24908,     0.24905,\n",
            "            0.24853,     0.24801,     0.24808,     0.24817,     0.24828,     0.24815,     0.24785,     0.24754,     0.24724,     0.24744,     0.24516,      0.2452,     0.24525,     0.24529,     0.24505,     0.24452,     0.24423,     0.24397,     0.24355,     0.24314,     0.24242,     0.24145,      0.2406,\n",
            "            0.23976,     0.23888,     0.23898,     0.23807,     0.23711,     0.23578,     0.23464,     0.23404,     0.23369,     0.23333,      0.2331,     0.23325,     0.23327,      0.2328,     0.23232,        0.23,     0.22913,     0.22859,      0.2287,     0.22855,     0.22832,     0.22808,     0.22784,\n",
            "            0.22761,     0.22631,     0.22633,     0.22634,     0.22635,     0.22637,     0.22638,     0.22639,     0.22641,     0.22642,     0.22643,     0.22645,     0.22646,     0.22626,     0.22574,     0.22526,     0.22529,     0.22531,     0.22534,     0.22537,      0.2254,     0.22465,     0.22332,\n",
            "              0.223,     0.22303,     0.22305,     0.22308,     0.22311,     0.22313,     0.22235,     0.22173,     0.22134,     0.22095,     0.22075,     0.22095,     0.22088,     0.22073,     0.22058,     0.22044,     0.22029,     0.22014,     0.21999,     0.21985,     0.21982,     0.21991,     0.21961,\n",
            "            0.21914,     0.21869,     0.21847,     0.21825,     0.21803,     0.21781,     0.21759,     0.21729,      0.2169,     0.21651,     0.21606,     0.21549,     0.21477,     0.21308,     0.21172,     0.21113,     0.21082,     0.21051,      0.2102,     0.20981,     0.20937,     0.20894,     0.20897,\n",
            "            0.20776,     0.20784,      0.2079,     0.20793,     0.20796,     0.20799,     0.20801,     0.20804,     0.20686,     0.20689,     0.20601,     0.20588,     0.20595,     0.20602,     0.20609,     0.20538,     0.20342,     0.20229,     0.20195,     0.20162,     0.20128,     0.19977,     0.19941,\n",
            "            0.19905,      0.1987,     0.19793,     0.19718,     0.19672,     0.19626,     0.19483,     0.19367,     0.19379,     0.19259,     0.19264,     0.19251,     0.19119,     0.19079,     0.19039,     0.19005,     0.18981,     0.18958,     0.18934,      0.1891,     0.18887,      0.1879,     0.18761,\n",
            "            0.18764,     0.18767,      0.1877,     0.18745,     0.18692,     0.18632,     0.18497,     0.18395,      0.1829,      0.1828,     0.18254,     0.18167,     0.18028,      0.1803,     0.18032,     0.18034,     0.18036,     0.18038,     0.18034,     0.18011,     0.17988,     0.17965,     0.17942,\n",
            "            0.17919,     0.17871,      0.1781,     0.17701,     0.17501,     0.17467,     0.17434,       0.174,     0.17362,     0.17323,     0.17283,     0.17246,      0.1721,     0.17175,      0.1714,     0.16975,      0.1694,     0.16904,     0.16868,     0.16807,     0.16745,     0.16471,     0.16405,\n",
            "            0.16346,     0.16366,     0.16147,     0.16094,     0.16078,     0.16063,     0.16047,     0.16031,     0.16016,        0.16,     0.15984,     0.15965,     0.15928,      0.1589,     0.15853,     0.15732,     0.15566,     0.15467,     0.15267,     0.15116,     0.15041,     0.14988,     0.14936,\n",
            "            0.14877,      0.1481,     0.14729,     0.14612,     0.14474,     0.14432,      0.1439,       0.142,     0.14125,      0.1408,     0.14051,     0.14022,     0.13993,     0.13964,     0.13902,     0.13839,     0.13791,     0.13746,       0.137,     0.13579,     0.13527,     0.13491,     0.13455,\n",
            "            0.13417,     0.13341,     0.13277,     0.13247,     0.13218,     0.13188,     0.13158,      0.1315,     0.13153,     0.13156,     0.13016,     0.12987,     0.12958,     0.12929,     0.12901,     0.12776,     0.12723,     0.12696,     0.12669,     0.12642,     0.12615,     0.12565,     0.12508,\n",
            "            0.12358,     0.12267,     0.12045,     0.11997,     0.11948,     0.11779,     0.11689,      0.1163,     0.11591,     0.11553,     0.11515,     0.11377,      0.1138,     0.11333,     0.11218,     0.11091,     0.11048,     0.11006,     0.10961,     0.10814,     0.10776,     0.10739,     0.10701,\n",
            "            0.10649,     0.10582,     0.10476,     0.10307,      0.1014,     0.10084,     0.10044,     0.10004,    0.099475,    0.098586,     0.09636,    0.094301,    0.093812,    0.093489,    0.093166,    0.092843,    0.092401,    0.091832,    0.091262,    0.090808,    0.090357,    0.089906,    0.088751,\n",
            "           0.086705,    0.086122,    0.085539,     0.08503,    0.084522,    0.083963,    0.083077,    0.081753,    0.080673,    0.079898,    0.079278,    0.078691,    0.078202,     0.07789,    0.077578,    0.077266,    0.076953,    0.075482,    0.073497,    0.072941,    0.072464,    0.072263,    0.072062,\n",
            "           0.071861,     0.07166,    0.071459,    0.071258,    0.071057,    0.069812,    0.069203,    0.068734,    0.068265,    0.067253,    0.065135,    0.064988,    0.064842,    0.064695,    0.064549,    0.064402,    0.064255,    0.064109,    0.063962,    0.063816,    0.062235,    0.062014,    0.061794,\n",
            "           0.061574,    0.061353,    0.061133,    0.060912,    0.059989,     0.05689,     0.05618,    0.055921,    0.055662,    0.055403,    0.055144,    0.054885,    0.054422,    0.053954,    0.053485,    0.053294,     0.05317,    0.053046,    0.052923,    0.052799,    0.052675,     0.05255,    0.052426,\n",
            "           0.052302,    0.052178,    0.052054,     0.05193,     0.05077,    0.048459,    0.047757,    0.045472,    0.043887,    0.042993,     0.04233,    0.041679,    0.040524,    0.039943,     0.03995,    0.039957,    0.039964,    0.039973,    0.039987,    0.039906,    0.039062,    0.038208,    0.037333,\n",
            "           0.036378,    0.035398,    0.034694,     0.03399,    0.033663,    0.033359,    0.033055,    0.032751,    0.032446,    0.032171,    0.031896,    0.031621,    0.031347,    0.031072,    0.030773,     0.03044,    0.030107,    0.029774,     0.02944,    0.028765,    0.028026,    0.027527,    0.027095,\n",
            "           0.026663,    0.026337,    0.026342,    0.026346,    0.026351,    0.026355,    0.026234,    0.026012,    0.025791,     0.02557,    0.025348,    0.025126,    0.024905,    0.024827,    0.024829,    0.024832,    0.024834,    0.024836,    0.024838,     0.02484,    0.024843,    0.024845,    0.024452,\n",
            "           0.024043,    0.023633,    0.022617,    0.021046,    0.020212,    0.020088,    0.019963,    0.019839,    0.019714,     0.01959,    0.019465,    0.019341,    0.019216,    0.019091,    0.018967,    0.018842,    0.018717,    0.018593,    0.018469,    0.018344,     0.01822,    0.018095,    0.017971,\n",
            "           0.017847,    0.017722,    0.017598,    0.017473,    0.017349,    0.017224,    0.017034,    0.016739,    0.016444,    0.016148,    0.015853,    0.015552,    0.015223,    0.014894,    0.014564,    0.014235,    0.014053,    0.014056,    0.014059,    0.014062,    0.013792,    0.013485,    0.013178,\n",
            "            0.01287,    0.012562,    0.012409,    0.012288,    0.012167,    0.012046,    0.011924,    0.011803,    0.011682,     0.01156,    0.011439,    0.011317,    0.011196,    0.011075,    0.010952,    0.010683,    0.010415,    0.010147,   0.0098783,   0.0096097,   0.0093335,   0.0090282,   0.0087228,\n",
            "          0.0084173,   0.0081118,   0.0078185,   0.0076354,   0.0074524,   0.0072693,   0.0070861,   0.0069029,   0.0067197,   0.0065365,   0.0063532,   0.0062129,   0.0061051,   0.0059972,   0.0058893,   0.0057814,   0.0056735,   0.0055655,   0.0054576,   0.0053496,   0.0052417,   0.0051337,   0.0050257,\n",
            "          0.0049177,   0.0048097,   0.0047079,   0.0046856,   0.0046633,    0.004641,   0.0046187,   0.0045964,   0.0045741,   0.0045518,   0.0045294,   0.0045071,   0.0044848,   0.0044625,   0.0044402,   0.0044179,   0.0043955,   0.0043732,   0.0043509,   0.0043286,   0.0043063,   0.0042839,   0.0042616,\n",
            "          0.0042393,    0.004217,   0.0041947,   0.0041723,     0.00415,   0.0041277,   0.0041054,    0.004083,   0.0040607,   0.0040384,   0.0040161,   0.0039937,   0.0039714,   0.0039491,   0.0039268,   0.0039044,   0.0038821,   0.0038598,   0.0038374,   0.0038151,   0.0037928,   0.0037704,   0.0037481,\n",
            "          0.0037258,   0.0037034,   0.0036811,   0.0036588,   0.0036364,   0.0036141,   0.0035918,   0.0035694,   0.0035471,   0.0035248,   0.0035024,   0.0034801,   0.0034577,   0.0034354,   0.0034131,   0.0033907,   0.0033684,    0.003346,   0.0033237,   0.0033014,    0.003279,   0.0032567,   0.0032343,\n",
            "           0.003212,   0.0031896,   0.0031673,   0.0031449,   0.0030644,   0.0029757,    0.002887,   0.0027983,   0.0027096,   0.0026209,   0.0025321,   0.0024434,   0.0023547,   0.0022659,   0.0021771,   0.0020883,   0.0019996,   0.0019108,    0.001822,   0.0017332,   0.0016444,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.10032,     0.10037,     0.13827,     0.16658,     0.18857,     0.20325,     0.21952,     0.23238,     0.24436,     0.25367,     0.26593,     0.27338,     0.28183,     0.28889,     0.30061,     0.30978,     0.31633,     0.32314,     0.32638,     0.33329,     0.34156,     0.34941,     0.35553,\n",
            "            0.36024,     0.36371,     0.36792,      0.3721,     0.37742,     0.38255,     0.38493,     0.38845,     0.39639,     0.40502,     0.40941,     0.41651,     0.42095,     0.42643,      0.4312,     0.43651,     0.43951,     0.44479,     0.45015,     0.45509,     0.45949,     0.46806,     0.47522,\n",
            "             0.4822,     0.48423,     0.48578,     0.48975,     0.49156,     0.49442,     0.49395,     0.49809,     0.49997,     0.50793,     0.51254,     0.51469,     0.51757,      0.5198,     0.52398,     0.52572,     0.52906,       0.533,     0.53541,      0.5371,     0.53792,     0.53942,     0.53974,\n",
            "            0.54017,     0.54164,     0.54518,     0.54416,      0.5463,     0.54631,     0.55243,     0.55218,     0.55609,     0.55978,     0.56007,     0.55927,     0.55893,     0.56472,     0.56812,     0.57355,     0.57938,     0.57975,     0.57958,     0.58101,     0.58206,     0.58384,     0.58733,\n",
            "            0.59245,     0.59535,     0.59585,     0.59833,     0.60144,     0.60325,     0.60623,     0.60731,     0.60844,     0.61159,     0.61432,     0.61679,      0.6155,     0.61876,     0.62039,      0.6256,     0.62874,      0.6322,     0.63782,     0.64028,     0.64126,     0.64171,     0.64397,\n",
            "            0.64366,     0.64521,     0.64768,     0.65246,     0.65631,     0.65659,     0.66305,      0.6685,     0.67024,     0.67119,     0.67167,     0.67092,     0.67306,     0.67379,     0.67453,     0.67409,     0.67561,     0.67587,     0.68327,     0.68614,     0.68576,     0.68484,     0.68268,\n",
            "            0.68696,     0.68972,     0.69139,     0.69971,     0.70185,     0.70679,     0.70671,      0.7089,     0.71003,     0.71116,     0.71594,     0.71969,      0.7207,     0.72171,     0.72292,     0.72422,     0.72708,     0.72714,     0.72864,     0.73061,     0.73243,     0.73314,     0.73276,\n",
            "            0.73238,      0.7341,     0.73598,     0.73804,     0.74099,      0.7431,     0.74545,     0.74709,     0.75057,     0.74978,     0.74941,     0.74903,      0.7511,     0.75241,     0.75316,     0.75391,     0.75467,     0.75826,     0.75894,     0.75963,     0.76031,     0.76394,     0.76744,\n",
            "            0.76921,     0.76918,     0.77334,     0.77816,     0.78392,     0.78498,     0.78577,     0.78657,     0.78736,     0.78718,      0.7868,     0.78789,      0.7909,     0.79393,     0.79509,     0.79626,     0.79752,     0.79883,     0.80028,     0.80297,     0.80872,     0.81114,     0.81296,\n",
            "             0.8126,     0.81223,     0.81401,     0.81585,     0.81834,     0.81926,     0.81905,     0.81884,     0.81864,     0.82474,     0.82474,     0.82568,     0.82662,     0.82756,     0.82788,     0.82753,     0.82946,     0.83083,     0.83056,     0.83029,     0.82981,     0.82917,     0.83235,\n",
            "             0.8318,     0.83927,     0.84174,     0.84225,     0.84164,     0.84079,     0.84005,     0.83966,     0.83943,      0.8392,     0.84002,     0.84402,     0.84722,     0.84692,     0.84663,     0.84514,     0.84458,     0.84474,     0.84773,     0.84837,     0.84822,     0.84807,     0.84792,\n",
            "            0.84777,     0.84697,     0.84735,     0.84772,     0.84809,     0.84846,     0.84883,      0.8492,     0.84958,     0.84995,     0.85032,     0.85069,     0.85106,     0.85115,     0.85082,     0.85058,     0.85136,     0.85215,     0.85293,     0.85371,      0.8545,     0.85445,     0.85361,\n",
            "            0.85396,     0.85474,     0.85551,     0.85628,     0.85706,     0.85783,     0.85741,     0.85702,     0.85678,     0.85654,     0.85781,     0.86386,     0.86552,     0.86543,     0.86534,     0.86525,     0.86517,     0.86508,     0.86499,      0.8649,     0.86624,     0.86876,     0.86938,\n",
            "             0.8691,     0.86884,     0.86871,     0.86858,     0.86845,     0.86833,      0.8682,     0.86802,     0.86779,     0.86755,     0.86729,     0.86695,     0.86651,     0.86549,     0.86465,     0.86428,     0.86409,      0.8639,      0.8637,     0.86346,     0.86319,     0.86291,     0.86678,\n",
            "            0.86725,     0.86985,     0.87222,      0.8732,     0.87418,     0.87515,     0.87613,     0.87711,     0.87869,     0.88163,     0.88113,      0.8877,     0.89038,     0.89302,     0.89562,     0.89659,      0.8956,     0.89502,     0.89484,     0.89467,      0.8945,      0.8937,     0.89351,\n",
            "            0.89332,     0.89313,     0.89272,     0.89232,     0.89207,     0.89182,     0.89103,     0.89544,     0.90083,     0.90291,     0.90518,      0.9072,     0.90656,     0.90636,     0.90616,     0.90599,     0.90588,     0.90576,     0.90564,     0.90552,     0.90541,     0.90492,     0.90577,\n",
            "            0.90726,     0.90874,     0.91023,     0.91083,     0.91057,     0.91028,     0.90963,     0.91254,     0.91498,     0.91878,     0.92129,     0.92091,     0.92106,      0.9221,     0.92313,     0.92416,      0.9252,     0.92623,     0.92698,     0.92689,     0.92679,      0.9267,      0.9266,\n",
            "            0.92651,     0.92631,     0.92605,     0.92559,     0.92472,     0.92458,     0.92443,     0.92428,     0.92411,     0.92394,     0.92376,      0.9236,     0.92344,     0.92328,     0.92312,     0.92237,      0.9222,     0.92204,     0.92187,     0.92158,     0.92129,     0.91998,     0.91965,\n",
            "            0.92088,     0.93442,     0.93352,     0.93329,     0.93323,     0.93316,     0.93309,     0.93303,     0.93296,     0.93289,     0.93283,     0.93275,     0.93259,     0.93243,     0.93227,     0.93174,       0.931,     0.93056,     0.92964,     0.92893,     0.92858,     0.92832,     0.92807,\n",
            "            0.92779,     0.92746,     0.92706,     0.92648,     0.92577,     0.92556,     0.92535,     0.92435,     0.92395,     0.92371,     0.92355,     0.92339,     0.92324,     0.92308,     0.92274,     0.92239,     0.92212,     0.92187,     0.92161,     0.92092,     0.92062,     0.92041,      0.9202,\n",
            "            0.91998,     0.91952,     0.91914,     0.91897,     0.91879,     0.91861,     0.91843,     0.92025,      0.9231,     0.92595,     0.92705,     0.92689,     0.92673,     0.92657,     0.92641,      0.9257,     0.92539,     0.92524,     0.92508,     0.92492,     0.92476,     0.92446,     0.92413,\n",
            "            0.92322,     0.93292,     0.93169,     0.93142,     0.93114,     0.93017,     0.92963,     0.92928,     0.92905,     0.92881,     0.92858,     0.93157,     0.93639,     0.93876,     0.93813,     0.93743,     0.93719,     0.93695,      0.9367,     0.93584,     0.93562,      0.9354,     0.93517,\n",
            "            0.93486,     0.93445,      0.9338,     0.93273,     0.93165,     0.93127,       0.931,     0.93073,     0.93035,     0.92973,     0.92815,     0.92662,     0.92625,       0.926,     0.92575,      0.9255,     0.92516,      0.9247,     0.92425,     0.92388,     0.92351,     0.92315,     0.92218,\n",
            "            0.92041,     0.91989,     0.91937,      0.9189,     0.91844,     0.91792,     0.91708,     0.91579,     0.91472,     0.91393,     0.91329,     0.91268,     0.91216,     0.91182,     0.91149,     0.91115,     0.91081,     0.90917,     0.90685,     0.90618,     0.90561,     0.90536,     0.90511,\n",
            "            0.90486,      0.9046,     0.90435,      0.9041,     0.90385,     0.90224,     0.90144,     0.90081,     0.90018,     0.89878,     0.89573,     0.89551,     0.89529,     0.89507,     0.89485,     0.89463,     0.89441,     0.89418,     0.89396,     0.89374,     0.89126,      0.8909,     0.89054,\n",
            "            0.89017,     0.88981,     0.88945,     0.88909,     0.88752,     0.88195,      0.8806,     0.88009,     0.87959,     0.87908,     0.87857,     0.87806,     0.87711,     0.87615,     0.87519,     0.87478,     0.87452,     0.87425,     0.87398,     0.87371,     0.87345,     0.87318,     0.87291,\n",
            "            0.87264,     0.87238,     0.87211,     0.87184,     0.86921,     0.86368,     0.86192,     0.85582,     0.85128,     0.84863,     0.84654,     0.84449,     0.84067,     0.84254,     0.84898,     0.85542,     0.86186,     0.87022,     0.88416,     0.89632,     0.89425,     0.89211,     0.88982,\n",
            "            0.88719,     0.88441,     0.88226,     0.88012,     0.87905,     0.87805,     0.87705,     0.87605,     0.87505,     0.87406,     0.87308,      0.8721,     0.87112,     0.87014,     0.86902,     0.86773,     0.86643,     0.86513,     0.86384,     0.86098,     0.85783,     0.85557,     0.85355,\n",
            "            0.85153,     0.85231,     0.86186,      0.8714,     0.88094,     0.89049,     0.89427,     0.89342,     0.89258,     0.89173,     0.89088,     0.89004,     0.88919,     0.89276,     0.89878,      0.9048,     0.91083,     0.91685,     0.92287,      0.9289,     0.93492,     0.94094,     0.94023,\n",
            "            0.93925,     0.93827,     0.93562,     0.93108,      0.9285,     0.92805,     0.92761,     0.92716,     0.92672,     0.92628,     0.92583,     0.92539,     0.92494,      0.9245,     0.92406,     0.92361,     0.92317,     0.92267,     0.92215,     0.92163,     0.92112,      0.9206,     0.92008,\n",
            "            0.91957,     0.91905,     0.91854,     0.91802,      0.9175,     0.91699,     0.91611,     0.91467,     0.91322,     0.91177,     0.91032,      0.9088,     0.90687,     0.90494,     0.90301,     0.90107,     0.91245,      0.9405,     0.96855,      0.9966,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.49253,     0.49253,     0.45083,     0.42801,     0.40755,     0.38552,      0.3753,     0.36349,     0.35484,     0.34225,     0.33547,     0.32573,     0.31865,     0.31078,     0.30921,     0.30448,     0.29898,     0.29426,     0.29032,     0.28482,     0.28245,     0.27852,     0.27459,\n",
            "            0.26987,     0.26751,     0.26279,     0.26121,     0.25885,     0.25728,     0.25413,     0.25188,     0.25098,     0.24959,     0.24784,     0.24469,     0.24154,     0.24076,     0.23918,     0.23839,     0.23603,     0.23446,      0.2321,      0.2321,     0.23131,     0.23131,     0.23131,\n",
            "            0.23053,     0.22895,     0.22738,     0.22581,     0.22345,     0.22187,     0.22041,      0.2203,     0.21951,     0.21951,     0.21873,     0.21873,     0.21777,     0.21637,     0.21558,     0.21322,     0.21243,     0.21243,     0.21243,     0.21179,     0.20974,     0.20928,     0.20771,\n",
            "            0.20703,     0.20692,     0.20535,     0.20299,     0.20179,     0.20085,     0.20063,     0.19888,     0.19748,     0.19748,     0.19532,     0.19369,     0.19276,     0.19197,     0.19119,     0.19119,     0.19074,      0.1904,     0.18961,     0.18961,     0.18883,     0.18725,     0.18647,\n",
            "            0.18647,     0.18647,     0.18489,     0.18411,     0.18332,     0.18175,     0.18048,     0.18017,     0.18017,     0.18017,     0.17939,     0.17729,     0.17632,     0.17624,     0.17624,     0.17624,     0.17624,     0.17581,     0.17545,     0.17506,     0.17467,     0.17388,     0.17362,\n",
            "            0.17231,     0.17231,     0.17211,     0.17152,     0.17128,     0.16999,     0.16994,     0.16977,     0.16916,     0.16916,       0.169,     0.16843,     0.16837,     0.16837,     0.16837,     0.16758,     0.16714,     0.16601,     0.16601,     0.16512,     0.16365,     0.16242,     0.16081,\n",
            "             0.1605,      0.1605,      0.1605,      0.1605,     0.15972,     0.15972,     0.15925,     0.15893,     0.15893,     0.15893,     0.15864,     0.15736,     0.15736,     0.15736,     0.15736,     0.15736,     0.15736,     0.15657,     0.15578,     0.15578,     0.15578,     0.15563,     0.15533,\n",
            "            0.15503,     0.15423,     0.15353,     0.15295,     0.15264,     0.15248,     0.15185,     0.15185,     0.15153,     0.15089,     0.15059,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.15028,     0.14949,\n",
            "            0.14947,      0.1487,      0.1487,      0.1487,      0.1487,      0.1487,      0.1487,      0.1487,      0.1487,     0.14842,     0.14808,     0.14792,     0.14792,     0.14792,     0.14792,     0.14792,     0.14792,     0.14792,     0.14792,     0.14792,     0.14792,     0.14713,     0.14705,\n",
            "             0.1467,     0.14635,     0.14634,     0.14634,     0.14634,     0.14622,     0.14602,     0.14581,     0.14561,     0.14555,     0.14398,     0.14398,     0.14398,     0.14398,     0.14381,     0.14345,     0.14319,     0.14297,      0.1427,     0.14242,     0.14194,     0.14129,     0.14062,\n",
            "            0.14007,     0.13926,     0.13926,     0.13863,     0.13799,     0.13711,     0.13637,     0.13597,     0.13574,      0.1355,     0.13533,     0.13533,     0.13525,     0.13494,     0.13463,     0.13311,     0.13254,     0.13218,     0.13218,     0.13206,     0.13191,     0.13176,      0.1316,\n",
            "            0.13145,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13061,     0.13047,     0.13013,     0.12982,     0.12982,     0.12982,     0.12982,     0.12982,     0.12982,     0.12933,     0.12846,\n",
            "            0.12825,     0.12825,     0.12825,     0.12825,     0.12825,     0.12825,     0.12774,     0.12733,     0.12708,     0.12684,     0.12667,     0.12667,     0.12659,      0.1265,      0.1264,     0.12631,     0.12621,     0.12612,     0.12602,     0.12593,     0.12589,     0.12589,     0.12568,\n",
            "            0.12538,     0.12509,     0.12495,      0.1248,     0.12466,     0.12452,     0.12438,     0.12419,     0.12394,     0.12369,      0.1234,     0.12304,     0.12257,      0.1215,     0.12063,     0.12025,     0.12006,     0.11986,     0.11966,     0.11941,     0.11914,     0.11886,      0.1188,\n",
            "            0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11723,      0.1172,     0.11664,     0.11644,     0.11644,     0.11644,     0.11644,     0.11597,     0.11474,     0.11403,     0.11382,     0.11361,      0.1134,     0.11245,     0.11223,\n",
            "            0.11201,     0.11178,      0.1113,     0.11083,     0.11055,     0.11026,     0.10937,     0.10858,     0.10858,     0.10779,     0.10779,     0.10768,     0.10686,     0.10661,     0.10637,     0.10616,     0.10601,     0.10587,     0.10572,     0.10557,     0.10543,     0.10483,     0.10464,\n",
            "            0.10464,     0.10464,     0.10464,     0.10448,     0.10415,     0.10378,     0.10295,     0.10228,      0.1016,     0.10149,     0.10131,     0.10078,    0.099921,    0.099921,    0.099921,    0.099921,    0.099921,    0.099921,    0.099886,    0.099746,    0.099606,    0.099466,    0.099326,\n",
            "           0.099186,    0.098898,    0.098525,    0.097865,     0.09665,    0.096447,    0.096244,     0.09604,    0.095812,    0.095574,    0.095336,    0.095109,    0.094895,    0.094682,    0.094469,    0.093479,    0.093265,    0.093051,    0.092834,    0.092465,    0.092095,    0.090452,    0.090057,\n",
            "           0.089693,    0.089683,    0.088381,    0.088062,    0.087969,    0.087876,    0.087783,     0.08769,    0.087596,    0.087503,     0.08741,    0.087295,    0.087074,    0.086852,    0.086631,     0.08591,    0.084928,    0.084344,    0.083164,    0.082273,     0.08183,    0.081522,    0.081215,\n",
            "            0.08087,    0.080475,    0.080001,    0.079315,    0.078505,    0.078262,    0.078019,    0.076905,    0.076469,    0.076208,    0.076039,     0.07587,    0.075701,    0.075533,    0.075172,    0.074809,    0.074528,    0.074265,    0.074003,    0.073299,    0.072997,    0.072789,    0.072582,\n",
            "           0.072363,    0.071921,    0.071552,    0.071381,     0.07121,    0.071039,    0.070868,     0.07081,     0.07081,     0.07081,    0.069994,    0.069828,    0.069662,    0.069496,     0.06933,    0.068616,    0.068313,    0.068159,    0.068004,    0.067849,    0.067694,    0.067405,    0.067082,\n",
            "           0.066221,    0.065652,    0.064387,    0.064112,    0.063837,    0.062878,    0.062368,    0.062029,    0.061813,    0.061597,    0.061381,    0.060582,    0.060582,    0.060306,    0.059656,    0.058943,    0.058702,    0.058461,    0.058214,    0.057384,    0.057174,    0.056963,    0.056752,\n",
            "           0.056459,    0.056086,    0.055495,    0.054547,    0.053619,    0.053307,    0.053084,    0.052862,    0.052547,    0.052053,    0.050818,    0.049679,    0.049408,     0.04923,    0.049051,    0.048873,    0.048629,    0.048315,    0.048001,    0.047751,    0.047502,    0.047254,    0.046619,\n",
            "           0.045495,    0.045176,    0.044856,    0.044577,      0.0443,    0.043993,    0.043509,    0.042786,    0.042197,    0.041775,    0.041437,    0.041118,    0.040852,    0.040683,    0.040513,    0.040344,    0.040174,    0.039375,      0.0383,       0.038,    0.037742,    0.037633,    0.037525,\n",
            "           0.037416,    0.037308,    0.037199,    0.037091,    0.036982,    0.036311,    0.035983,     0.03573,    0.035478,    0.034933,    0.033796,    0.033718,    0.033639,     0.03356,    0.033482,    0.033403,    0.033325,    0.033246,    0.033168,    0.033089,    0.032243,    0.032125,    0.032007,\n",
            "            0.03189,    0.031772,    0.031654,    0.031536,    0.031044,    0.029393,    0.029016,    0.028878,    0.028741,    0.028603,    0.028465,    0.028328,    0.028082,    0.027834,    0.027585,    0.027484,    0.027419,    0.027353,    0.027287,    0.027222,    0.027156,     0.02709,    0.027025,\n",
            "           0.026959,    0.026893,    0.026828,    0.026762,    0.026148,    0.024929,    0.024559,    0.023357,    0.022524,    0.022055,    0.021708,    0.021367,    0.020763,    0.020456,    0.020456,    0.020456,    0.020456,    0.020456,    0.020456,    0.020407,    0.019967,    0.019522,    0.019067,\n",
            "            0.01857,     0.01806,    0.017695,    0.017329,     0.01716,    0.017003,    0.016845,    0.016687,     0.01653,    0.016387,    0.016245,    0.016103,    0.015961,    0.015818,    0.015664,    0.015492,     0.01532,    0.015147,    0.014975,    0.014627,    0.014246,    0.013989,    0.013766,\n",
            "           0.013544,    0.013375,    0.013375,    0.013375,    0.013375,    0.013375,    0.013312,    0.013198,    0.013085,    0.012971,    0.012857,    0.012743,    0.012629,    0.012589,    0.012589,    0.012589,    0.012589,    0.012589,    0.012589,    0.012589,    0.012589,    0.012589,    0.012387,\n",
            "           0.012177,    0.011967,    0.011447,    0.010643,    0.010217,    0.010154,     0.01009,    0.010027,   0.0099631,   0.0098996,    0.009836,   0.0097724,   0.0097088,   0.0096453,   0.0095817,   0.0095181,   0.0094545,   0.0093911,   0.0093277,   0.0092643,   0.0092009,   0.0091375,   0.0090741,\n",
            "          0.0090107,   0.0089473,   0.0088839,   0.0088206,   0.0087572,   0.0086938,   0.0085972,   0.0084468,   0.0082965,   0.0081462,   0.0079959,   0.0078431,   0.0076758,   0.0075086,   0.0073413,    0.007174,    0.007081,    0.007081,    0.007081,    0.007081,   0.0069441,   0.0067883,   0.0066325,\n",
            "          0.0064767,   0.0063209,   0.0062434,    0.006182,   0.0061206,   0.0060592,   0.0059979,   0.0059365,   0.0058751,   0.0058137,   0.0057523,    0.005691,   0.0056296,   0.0055682,    0.005506,   0.0053704,   0.0052348,   0.0050992,   0.0049636,   0.0048281,   0.0046886,   0.0045346,   0.0043805,\n",
            "          0.0042265,   0.0040724,   0.0039246,   0.0038324,   0.0037401,   0.0036479,   0.0035557,   0.0034634,   0.0033712,   0.0032789,   0.0031867,   0.0031161,   0.0030619,   0.0030076,   0.0029533,   0.0028991,   0.0028448,   0.0027905,   0.0027363,    0.002682,   0.0026277,   0.0025735,   0.0025192,\n",
            "          0.0024649,   0.0024107,   0.0023595,   0.0023483,   0.0023371,   0.0023259,   0.0023147,   0.0023035,   0.0022923,   0.0022811,   0.0022699,   0.0022587,   0.0022474,   0.0022362,    0.002225,   0.0022138,   0.0022026,   0.0021914,   0.0021802,    0.002169,   0.0021578,   0.0021466,   0.0021354,\n",
            "          0.0021242,   0.0021129,   0.0021017,   0.0020905,   0.0020793,   0.0020681,   0.0020569,   0.0020457,   0.0020345,   0.0020233,   0.0020121,   0.0020009,   0.0019897,   0.0019784,   0.0019672,    0.001956,   0.0019448,   0.0019336,   0.0019224,   0.0019112,      0.0019,   0.0018888,   0.0018776,\n",
            "          0.0018664,   0.0018552,   0.0018439,   0.0018327,   0.0018215,   0.0018103,   0.0017991,   0.0017879,   0.0017767,   0.0017655,   0.0017543,   0.0017431,   0.0017319,   0.0017207,   0.0017094,   0.0016982,    0.001687,   0.0016758,   0.0016646,   0.0016534,   0.0016422,    0.001631,   0.0016198,\n",
            "          0.0016086,   0.0015974,   0.0015862,   0.0015749,   0.0015346,   0.0014901,   0.0014456,   0.0014011,   0.0013566,   0.0013122,   0.0012677,   0.0012232,   0.0011787,   0.0011342,   0.0010897,   0.0010453,   0.0010008,   0.0009563,  0.00091182,  0.00086734,  0.00082285,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: np.float64(0.14072392786129723)\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,\n",
            "           0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,\n",
            "           0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,\n",
            "           0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582,     0.12582])\n",
            "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
            "nt_per_class: array([1271,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
            "nt_per_image: array([423,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "results_dict: {'metrics/precision(B)': np.float64(0.5125382915180323), 'metrics/recall(B)': np.float64(0.2187254130605822), 'metrics/mAP50(B)': np.float64(0.2748901143648725), 'metrics/mAP50-95(B)': np.float64(0.12581657380534442), 'fitness': np.float64(0.14072392786129723)}\n",
            "save_dir: PosixPath('runs/detect/val2')\n",
            "speed: {'preprocess': 0.36208753488374207, 'inference': 1.8328883062020556, 'loss': 0.0008233391490860011, 'postprocess': 2.268350943796055}\n",
            "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
            "task: 'detect'\n"
          ]
        }
      ],
      "source": [
        "# Evaluates the trained model using the TEST SET defined in data.yaml\n",
        "\n",
        "metrics_YOLOv8n = model_YOLOv8n.val(data='data.yaml', split='test') # returns accuracy metrics (e.g., mAP, precision, recall, etc.) on the test set\n",
        "print(\"Test metrics:\", metrics_YOLOv8n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmdyUMPKd_V8"
      },
      "source": [
        "Confidence (confidence) is the probability estimated by the model that a detected object is actually real (i.e., not a false positive)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the fine-tuned model with the weights saved in _best_yolov8n.pt_, perform inference on all images in the folder, and save the annotated images (i.e., the original images with the bounding boxes drawn on them) into a directory"
      ],
      "metadata": {
        "id": "_f0aAJ734A9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2s3bR6w3Yjv",
        "outputId": "408473d3-b100-4ac9-ac3b-dc6d0b3f640c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#  Inference (practical use of the fine-tuned model)\n",
        "\n",
        "# Load the best weights found\n",
        "best_YOLOv8n = '/content/runs_finetune/person_yolov8n2/weights/best_yolov8n.pt'\n",
        "model_inf_YOLOv8n = YOLO(best_YOLOv8n) # Creates a new model instance by loading the best weights\n",
        "\n",
        "# Performs inference on one or more images, or on a video, by specifying the path in the source parameter.\n",
        "# conf=0.25 → Confidence threshold for considering a detection valid.\n",
        "preds_YOLOv8n = model_inf_YOLOv8n.predict(\n",
        "  # source='/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/test/images',\n",
        "  source='/content/AERALIS_YOLOv8n_local/test/images',\n",
        "  conf=0.25,\n",
        "  verbose=False, # disable on-screen printing\n",
        "  save=True\n",
        ")\n",
        "\n",
        "# Too many images to show!\n",
        "# for result in preds_YOLOv8n:\n",
        "#    result.show() # displays the predictions (eventually you can also save them)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJS_ZLwznJS9"
      },
      "source": [
        "In order to use it on the Jetson Nano we now want to download the model, so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Vk8Pg-kKMGW"
      },
      "outputs": [],
      "source": [
        "# Create folders on Google Drive (first time only):\n",
        "!mkdir -p /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/results/annotated\n",
        "!mkdir -p /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbYQ5wv5Kac9"
      },
      "outputs": [],
      "source": [
        "# Copy annotated images:\n",
        "!cp -r /content/runs/detect/predict/* /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/results/annotated/\n",
        "\n",
        "# Copy the best weights (best.pt) after training:\n",
        "!cp /content/runs_finetune/person_yolov8n2/weights/best.pt /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-qaF-hFnTnC"
      },
      "outputs": [],
      "source": [
        "# To download it directly to the computer:\n",
        "from google.colab import files\n",
        "files.download('/content/runs_finetune/person_yolov8n/weights/best_yolov8n.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veHRWTjpnk34"
      },
      "source": [
        "When we have the .pt file on the PC, we could:\n",
        "- Upload it to the Jetson Nano,\n",
        "- Convert it to ONNX/TensorRT if you need it for optimization,\n",
        "- Use it with the PyTorch/Ultralytics version on any computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQv-8zHUOLde"
      },
      "source": [
        "Weight access code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbx4l9dVOKhY"
      },
      "outputs": [],
      "source": [
        "# Path of saved weights:\n",
        "weights_path_YOLOv8n = '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.pt'\n",
        "model_YOLOv8n = YOLO(weights_path_YOLOv8n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp2RfzXhOO1U"
      },
      "source": [
        "Access code for annotated images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU2quOVVSu0A"
      },
      "outputs": [],
      "source": [
        "# Directory of annotated images\n",
        "annotated_dir = '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/results/annotated'\n",
        "\n",
        "# Get all the .jpg files in the directory\n",
        "annotated_imgs_YOLOv8n = [\n",
        "  os.path.join(annotated_dir, f)\n",
        "  for f in os.listdir(annotated_dir)\n",
        "  if f.lower().endswith('.jpg')\n",
        "]\n",
        "\n",
        "# View the first 5 annotated images\n",
        "for img_path in annotated_imgs_YOLOv8n[:5]:\n",
        "  img = Image.open(img_path)\n",
        "  img.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n4EVx_z57Io"
      },
      "source": [
        "### YOLOv11n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfcXa428v5ux"
      },
      "source": [
        "Ora eseguiamo lo stesso procedimento per YOLOv11n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBAol2_a3F4d",
        "outputId": "54f18121-6171-4dbb-ed16-f499f1a01ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy completed: True\n"
          ]
        }
      ],
      "source": [
        "src_yolov11n = '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n'\n",
        "dst_yolov11n = '/content/AERALIS_YOLOv11n_local'  # is now on the local VM, NOT on drive\n",
        "\n",
        "# If the destination folder already exists, I delete it\n",
        "if os.path.exists(dst_yolov11n):\n",
        "  shutil.rmtree(dst_yolov11n)\n",
        "\n",
        "# Recursive copy of ENTIRE folder (and subfolders)\n",
        "shutil.copytree(src_yolov11n, dst_yolov11n)\n",
        "print(\"Copy completed:\", os.path.exists(dst_yolov11n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO8YB8G43Kkr",
        "outputId": "811954f0-bb62-485c-8bf2-8f8e04e4875d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   55G   58G  49% /\n"
          ]
        }
      ],
      "source": [
        "!df -h / # It shows the total, used and free space on the root (/) of the Colab VM.\n",
        "\n",
        "# Avail column: space still available for your files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbpl3LPY3NJV",
        "outputId": "9d5cd061-5ad0-49dc-ab1a-1c4ac35ce250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.6G\t/content/AERALIS_YOLOv11n_local\n"
          ]
        }
      ],
      "source": [
        "# Show space used by your local folder\n",
        "!du -sh /content/AERALIS_YOLOv11n_local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmqFX4xo3P5E",
        "outputId": "29a21efc-8dd0-42b2-a051-35a607d1ed52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140K\t/content/.config\n",
            "6.6G\t/content/AERALIS_YOLOv11n_local\n",
            "du: cannot access '/content/drive/.Encrypted/.shortcut-targets-by-id/1LQbD7p_iS5KLqGNdfrYEvsAx0i_bgB0h/projectUPV': No such file or directory\n",
            "69G\t/content/drive\n",
            "55M\t/content/sample_data\n",
            "75G\t/content/\n"
          ]
        }
      ],
      "source": [
        "# Show space occupied by various folders in /content/.\n",
        "!du -h --max-depth=1 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7CtXM7O3Uu9",
        "outputId": "cd8d3ea2-f93c-4b8e-8271-5e4392a0dddf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YAML dataset (edit routes)\n",
        "data_yaml_yolov11n = \"\"\"\n",
        "train: /content/AERALIS_YOLOv11n_local/train/images\n",
        "val:   /content/AERALIS_YOLOv11n_local/val/images\n",
        "test:  /content/AERALIS_YOLOv11n_local/test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['person']\n",
        "\"\"\"\n",
        "open('data.yaml', 'w').write(data_yaml_yolov11n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGDA_FB5zV1F",
        "outputId": "5e63e516-f422-4e60-b12c-52c661f3861f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 432MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Upload the pre-trained model we want to use as a starting point\n",
        "\n",
        "model_YOLOv11n = YOLO('yolo11n.pt') # it is the model that will be fine-tuned on the custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo3UQF95vbjy",
        "outputId": "60e0761e-bf4e-490c-fa95-a98a20c00704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# To see the available GPU\n",
        "import torch\n",
        "print(torch.cuda.is_available()) # True = you have GPU --> if False then use device='cpu'\n",
        "print(torch.cuda.device_count()) # Name of GPU\n",
        "\n",
        "# If True and at least 1, you can use device=0.\n",
        "# If you don't have GPU: use device='cpu' (much slower).\n",
        "# Locally (not Colab): check with nvidia-smi from terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBBPkeikYhDS",
        "outputId": "8054841d-ec1f-4a04-d3c4-5d0d2193e957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=person_yolov11n, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_finetune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs_finetune/person_yolov11n, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 19.5MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2916.3±1744.5 MB/s, size: 2026.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/AERALIS_YOLOv11n_local/train/labels... 2395 images, 388 backgrounds, 0 corrupt: 100%|██████████| 2395/2395 [00:01<00:00, 1677.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/AERALIS_YOLOv11n_local/train/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 4029.4±2087.3 MB/s, size: 2606.8 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/AERALIS_YOLOv11n_local/val/labels... 515 images, 75 backgrounds, 0 corrupt: 100%|██████████| 515/515 [00:00<00:00, 1544.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/AERALIS_YOLOv11n_local/val/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs_finetune/person_yolov11n/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns_finetune/person_yolov11n\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      2.35G      2.228       3.31      1.089         61        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:08<00:00,  1.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.567      0.447      0.451      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      2.44G      2.186      1.962      1.079         52        640: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.575      0.378      0.422      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      2.46G      2.179      1.566      1.088         50        640: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.669        0.5      0.537      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      2.47G      2.109      1.435      1.065         39        640: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258        0.7      0.508       0.55      0.222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      2.49G      2.076      1.335      1.056         45        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.713      0.541       0.58      0.236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100       2.5G      2.024      1.253      1.047         37        640: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.704       0.56      0.594      0.253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      2.52G      1.993      1.258      1.039         47        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.694       0.49      0.542      0.223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100      2.53G      1.977      1.192      1.023         39        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.721      0.561      0.602      0.248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      2.55G      1.922      1.139      1.003         40        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.823      0.584      0.659      0.296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100      2.56G      1.894        1.1      1.005         61        640: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.787       0.58      0.651      0.287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      2.58G      1.891      1.107     0.9989         40        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.786      0.591      0.647      0.292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      2.59G      1.845      1.073     0.9877         42        640: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.78        0.6      0.668      0.303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      2.61G      1.833      1.058     0.9868         47        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.745      0.593      0.641      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      2.62G      1.818      1.042     0.9823         36        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.772      0.626      0.685      0.303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      2.64G      1.818      1.024     0.9825         61        640: 100%|██████████| 150/150 [01:08<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.769        0.6      0.665      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      2.65G      1.793      1.017     0.9739         41        640: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.814      0.605      0.698      0.337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      2.67G      1.776      1.001     0.9732         61        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.85      0.617      0.704      0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      2.68G      1.784     0.9895     0.9729         65        640: 100%|██████████| 150/150 [01:09<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.794      0.617      0.691      0.325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100       2.7G      1.765     0.9795     0.9651         66        640: 100%|██████████| 150/150 [01:10<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.789      0.616      0.677      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      2.71G      1.746     0.9641     0.9622         29        640: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.801      0.628      0.693      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      2.73G      1.743     0.9615     0.9586         65        640: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.816      0.626      0.721       0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      2.74G      1.736     0.9486     0.9558         39        640: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.82      0.621      0.703      0.347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      2.75G      1.699     0.9304      0.953         42        640: 100%|██████████| 150/150 [01:10<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.805      0.656      0.724      0.356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      2.77G      1.678     0.9007      0.954         57        640: 100%|██████████| 150/150 [01:09<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.808      0.656       0.74      0.363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      2.79G      1.675     0.9041     0.9448         44        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.815      0.648      0.725      0.352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100       2.8G      1.682     0.9133     0.9542         65        640: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.827      0.653      0.726      0.365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      2.81G      1.683     0.9205      0.949         52        640: 100%|██████████| 150/150 [01:08<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.829      0.651      0.733      0.349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      2.83G      1.666     0.8888     0.9442         42        640: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.835      0.657       0.74      0.368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      2.84G      1.667     0.8914     0.9459         55        640: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.856      0.615      0.729      0.356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      2.86G      1.632     0.8742     0.9386         36        640: 100%|██████████| 150/150 [01:09<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.838      0.665      0.737      0.351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      2.87G      1.633     0.8677     0.9398         49        640: 100%|██████████| 150/150 [01:11<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.827      0.679      0.749      0.366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      2.89G      1.627     0.8686     0.9434         56        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.818      0.645      0.712      0.356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100       2.9G      1.643     0.8805     0.9426         44        640: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.825      0.686      0.757      0.373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      2.92G      1.585     0.8505     0.9295         55        640: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.827      0.693      0.764      0.377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      2.93G      1.616     0.8578     0.9349         31        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.868      0.672      0.768      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      2.95G      1.611     0.8434     0.9296         32        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.881      0.695      0.784      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      2.96G      1.585     0.8318      0.927         47        640: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873      0.696      0.788      0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      2.98G      1.543     0.8215     0.9148         47        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.86      0.703      0.788      0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100      2.99G      1.559     0.8074     0.9206         68        640: 100%|██████████| 150/150 [01:11<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.836      0.702      0.782      0.384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      3.01G      1.568     0.8212     0.9258         42        640: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.838      0.702      0.776      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      3.02G      1.541     0.8131     0.9252         40        640: 100%|██████████| 150/150 [01:09<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.85      0.693      0.781      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      3.04G      1.544     0.8065     0.9149         52        640: 100%|██████████| 150/150 [01:07<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.863      0.718      0.793      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      3.05G      1.568     0.8091     0.9157         44        640: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.847      0.724        0.8      0.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      3.07G      1.559     0.8103     0.9204        102        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.881      0.713      0.797      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      3.08G      1.539     0.7987     0.9149         66        640: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.858      0.734      0.809      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100       3.1G       1.53      0.787      0.914         31        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882      0.712      0.794      0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      3.11G      1.514      0.794     0.9142         41        640: 100%|██████████| 150/150 [01:09<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.896      0.721      0.812      0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      3.12G      1.515     0.7785     0.9114         40        640: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.867      0.707      0.806      0.412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      3.14G      1.501     0.7769     0.9083         34        640: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.895      0.719      0.813      0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      3.15G      1.493     0.7717     0.9041         24        640: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.86      0.742      0.815      0.421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      3.17G       1.46     0.7535     0.9024         59        640: 100%|██████████| 150/150 [01:07<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873       0.72        0.8       0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      3.19G      1.497     0.7668     0.9075         31        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882      0.713      0.806      0.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100       3.2G      1.479      0.756     0.8978         51        640: 100%|██████████| 150/150 [01:07<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.857      0.729      0.805      0.417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      3.21G      1.501     0.7605     0.9015         50        640: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.874      0.734      0.813      0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100      3.23G       1.47      0.751      0.905         29        640: 100%|██████████| 150/150 [01:08<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.87      0.738      0.809      0.422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      3.25G       1.46     0.7459     0.9024         44        640: 100%|██████████| 150/150 [01:09<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.884      0.721      0.822      0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      3.26G      1.462     0.7434     0.9085         36        640: 100%|██████████| 150/150 [01:05<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.914      0.736       0.83      0.438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      3.27G      1.426     0.7235     0.8973         80        640: 100%|██████████| 150/150 [01:08<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.872      0.756      0.833      0.432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      3.29G      1.457     0.7424      0.898         29        640: 100%|██████████| 150/150 [01:07<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.738      0.821      0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100       3.3G      1.431     0.7284     0.9055         60        640: 100%|██████████| 150/150 [01:07<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.869       0.75      0.824      0.429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      3.32G      1.445     0.7245     0.9006         41        640: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.877      0.757      0.828      0.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      3.33G      1.438     0.7284     0.8974         32        640: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.903      0.748       0.83      0.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/100      3.35G      1.401     0.7099     0.8905         64        640: 100%|██████████| 150/150 [01:08<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.871      0.752       0.83      0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     64/100      3.36G      1.428     0.7143     0.8919         63        640: 100%|██████████| 150/150 [01:08<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.749      0.828      0.436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     65/100      3.38G      1.396     0.7025     0.8887         43        640: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.87       0.76      0.827      0.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     66/100      3.39G      1.397     0.6991     0.8898         72        640: 100%|██████████| 150/150 [01:10<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.875      0.767       0.84      0.436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     67/100      3.41G      1.396     0.6988     0.8843         56        640: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.896       0.73      0.829      0.437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     68/100      3.52G      1.411      0.706     0.8928         39        640: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.862      0.757      0.832      0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     69/100      3.54G      1.381     0.6903     0.8856         55        640: 100%|██████████| 150/150 [01:07<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.855      0.767      0.837      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     70/100      3.55G      1.365     0.6799     0.8802         28        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.86       0.77      0.838      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     71/100      3.57G      1.378     0.6846     0.8813         22        640: 100%|██████████| 150/150 [01:08<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.878      0.754      0.837      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     72/100      3.58G      1.371     0.6867     0.8768         58        640: 100%|██████████| 150/150 [01:08<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873      0.743      0.831      0.437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     73/100       3.6G      1.365     0.6794     0.8799         50        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.888      0.749      0.835      0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     74/100      3.61G      1.372     0.6757     0.8817         49        640: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.748       0.84      0.452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     75/100      3.63G      1.364     0.6763     0.8801         43        640: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258        0.9      0.756      0.844      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     76/100      3.64G      1.348     0.6725     0.8807         31        640: 100%|██████████| 150/150 [01:09<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886       0.75      0.839      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     77/100      3.66G      1.368     0.6758     0.8816         45        640: 100%|██████████| 150/150 [01:07<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.895      0.761      0.842      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     78/100      3.67G      1.359     0.6749     0.8766         29        640: 100%|██████████| 150/150 [01:07<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.885      0.762      0.853      0.466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     79/100      3.69G       1.33     0.6528     0.8795         44        640: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.861      0.779      0.845      0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     80/100       3.7G      1.333     0.6557      0.877         42        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.891       0.75      0.846      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     81/100      3.72G      1.323     0.6499     0.8796         65        640: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.89      0.782      0.853      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     82/100      3.73G      1.308     0.6427      0.871         49        640: 100%|██████████| 150/150 [01:11<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.881      0.777      0.856      0.466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     83/100      3.75G      1.336     0.6552     0.8717         40        640: 100%|██████████| 150/150 [01:09<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.892      0.769       0.85      0.467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     84/100      3.76G      1.327     0.6514     0.8741         66        640: 100%|██████████| 150/150 [01:08<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882       0.77      0.849      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     85/100      3.78G      1.308     0.6499     0.8738         40        640: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.896      0.762      0.849      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     86/100      3.79G      1.298     0.6292     0.8691         50        640: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.892      0.762      0.847      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     87/100       3.8G      1.311     0.6404     0.8697         43        640: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.888      0.762      0.847      0.468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     88/100      3.82G        1.3      0.639     0.8654         42        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.888      0.775      0.855      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     89/100      3.83G      1.313     0.6388     0.8733         43        640: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.907      0.761      0.861      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     90/100      3.85G      1.278     0.6316     0.8672         28        640: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.778      0.859      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     91/100      3.86G      1.308      0.642     0.8773         22        640: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258       0.88      0.781      0.856      0.467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     92/100      3.88G      1.287     0.6271     0.8715         36        640: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.878      0.775      0.848      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     93/100      3.89G       1.26     0.6184      0.867         23        640: 100%|██████████| 150/150 [01:15<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882      0.777      0.856      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     94/100      3.91G      1.247     0.6136     0.8653         35        640: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.886      0.772      0.854      0.467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     95/100      3.92G      1.252     0.6071     0.8662         23        640: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.884      0.771      0.855      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     96/100      3.94G      1.262     0.6115     0.8725         18        640: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.878      0.782      0.852      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     97/100      3.95G      1.236     0.5945     0.8627         21        640: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.877      0.789      0.857      0.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     98/100      3.97G      1.212     0.5846     0.8572         32        640: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.873       0.79      0.858      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     99/100      3.98G      1.212     0.5884     0.8579         29        640: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.882      0.783      0.858      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "    100/100         4G       1.22     0.5835     0.8653         15        640: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.877      0.786      0.858      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "100 epochs completed in 2.197 hours.\n",
            "Optimizer stripped from runs_finetune/person_yolov11n/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs_finetune/person_yolov11n/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs_finetune/person_yolov11n/weights/best.pt...\n",
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        515       1258      0.887      0.778      0.859      0.479\n",
            "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns_finetune/person_yolov11n\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Fine‑tuning\n",
        "results_YOLOv11n = model_YOLOv11n.train(\n",
        "  data='data.yaml',\n",
        "  epochs=100,\n",
        "  imgsz=640,\n",
        "  batch=16,\n",
        "  patience=20,\n",
        "  workers=2,\n",
        "  device=0,\n",
        "  project='runs_finetune',\n",
        "  name='person_yolov11n'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml_yolov11n = \"\"\"\n",
        "train: /content/AERALIS_YOLOv11n_local/train/images\n",
        "val:   /content/AERALIS_YOLOv11n_local/val/images\n",
        "test:  /content/AERALIS_YOLOv11n_local/test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['person']\n",
        "\"\"\"\n",
        "\n",
        "with open('data.yaml', 'w') as f:\n",
        "  f.write(data_yaml_yolov11n)"
      ],
      "metadata": {
        "id": "OK3nRLoNMT3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg0cTtIOYg_7",
        "outputId": "3acb350e-6f33-4b7a-94b5-3b602dc9d8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2601.5±1168.5 MB/s, size: 2001.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/AERALIS_YOLOv11n_local/test/labels... 516 images, 93 backgrounds, 0 corrupt: 100%|██████████| 516/516 [00:00<00:00, 1605.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/AERALIS_YOLOv11n_local/test/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:06<00:00,  5.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        516       1271      0.554       0.23      0.297      0.128\n",
            "                person        423       1271      0.554       0.23      0.297      0.128\n",
            "Speed: 0.4ms preprocess, 1.5ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "Test metrics: ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e020b0def10>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.93939,     0.93939,     0.93939,     0.93939,\n",
            "            0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,     0.93939,\n",
            "            0.93939,     0.93939,     0.93939,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,\n",
            "            0.92857,     0.92857,     0.92857,     0.92233,     0.92233,     0.92233,      0.9115,      0.9115,      0.9115,      0.9115,      0.9115,      0.9115,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,\n",
            "            0.90909,     0.90909,     0.90909,      0.9058,      0.9058,      0.9058,      0.9058,     0.90141,     0.90141,     0.89583,     0.89474,     0.89474,     0.89474,     0.89474,     0.89474,     0.89032,     0.89032,     0.88535,     0.88272,     0.88272,     0.88272,     0.87952,     0.87952,\n",
            "              0.875,     0.87135,     0.87135,      0.8306,      0.8306,     0.82258,     0.80628,     0.79188,     0.77723,     0.77561,      0.7619,     0.76056,     0.76056,     0.75463,     0.74667,     0.74667,     0.74667,     0.74667,     0.74561,     0.74359,     0.74359,     0.74359,     0.74153,\n",
            "             0.7395,     0.73878,     0.73878,     0.73878,     0.73878,      0.7381,      0.7381,      0.7381,      0.7381,     0.73541,     0.73541,     0.73359,     0.73285,     0.73285,     0.73285,     0.73285,     0.73285,     0.73285,     0.73285,     0.73285,     0.73285,     0.73285,     0.72857,\n",
            "            0.71875,     0.71875,     0.71821,     0.71821,     0.71769,     0.71717,     0.71717,     0.70627,      0.7013,     0.70096,     0.70096,     0.69841,     0.69063,      0.6904,      0.6904,     0.68085,     0.67665,     0.66862,     0.66862,        0.66,        0.66,     0.65449,     0.65449,\n",
            "            0.63807,     0.63807,     0.63807,     0.63807,     0.63325,     0.63255,     0.62791,     0.62725,      0.6266,        0.62,        0.62,     0.61787,     0.61125,     0.61071,     0.60723,     0.60284,     0.60284,     0.59674,     0.59629,     0.59361,     0.59361,     0.58744,     0.58333,\n",
            "            0.58333,     0.58333,     0.58333,     0.57974,     0.57974,     0.57692,     0.57415,     0.57233,     0.57113,     0.57113,     0.57113,     0.57055,     0.57055,     0.56944,     0.56944,     0.56944,     0.56944,     0.56944,     0.56944,     0.56556,     0.56556,     0.55408,     0.55408,\n",
            "            0.55179,     0.55056,     0.53623,     0.53203,     0.53203,     0.53203,      0.5163,     0.51448,     0.51351,     0.51089,     0.50579,     0.50163,     0.49597,     0.49442,     0.49209,     0.49134,      0.4906,     0.48545,     0.48545,     0.48545,     0.48407,     0.47761,     0.47697,\n",
            "            0.47633,     0.47438,     0.47278,     0.47278,     0.47278,     0.47278,     0.47278,     0.47151,     0.46835,     0.46016,     0.46016,     0.45964,     0.44947,     0.44782,     0.44531,     0.44531,     0.44159,     0.44159,     0.43726,     0.43213,     0.41998,     0.41998,     0.41598,\n",
            "            0.41598,     0.41598,     0.41598,     0.40711,     0.40382,     0.40382,     0.40382,     0.39824,     0.39824,     0.39759,     0.39631,     0.39505,     0.39505,     0.39339,     0.39339,     0.38912,     0.38912,     0.38716,     0.38485,     0.38485,     0.38352,      0.3833,      0.3833,\n",
            "             0.3833,     0.38194,     0.38194,     0.38194,     0.38128,     0.38128,     0.38025,     0.37778,     0.37778,     0.37752,     0.37746,     0.37746,     0.37746,     0.37746,     0.37746,     0.37746,     0.37746,     0.37699,     0.37235,      0.3702,     0.36933,     0.36856,     0.36682,\n",
            "            0.36664,     0.36664,     0.36646,     0.36412,     0.36404,     0.36229,     0.36128,     0.36028,     0.35959,     0.35516,     0.35516,     0.35304,     0.34951,     0.34463,     0.34405,     0.34293,     0.34234,     0.33959,     0.33959,     0.33959,     0.33877,     0.33875,     0.33875,\n",
            "            0.33743,     0.33258,     0.33133,     0.32718,     0.32202,     0.32202,     0.31935,     0.31935,     0.31915,     0.31494,     0.31198,     0.31198,     0.30995,     0.30615,     0.30615,     0.30524,     0.30524,     0.30196,     0.30196,     0.29994,     0.29789,     0.29682,      0.2925,\n",
            "            0.29004,     0.28781,      0.2871,      0.2858,     0.28571,     0.28443,     0.28418,     0.28134,     0.27946,     0.27923,     0.27836,     0.27616,     0.27463,     0.27463,     0.27385,     0.27385,     0.27258,     0.27072,     0.27054,     0.27054,     0.27054,     0.26931,     0.26507,\n",
            "            0.26189,     0.26189,     0.26189,     0.26119,     0.26103,     0.26073,     0.25949,     0.25529,     0.25438,     0.25437,     0.25334,     0.25334,     0.25221,     0.24976,     0.24976,     0.24916,     0.24797,     0.24786,     0.24786,     0.24599,     0.24369,     0.24369,     0.24369,\n",
            "            0.24369,     0.24369,     0.24369,     0.24369,     0.24337,     0.23765,     0.23558,     0.23519,      0.2347,     0.23253,     0.23057,     0.22963,     0.22944,     0.22944,     0.22567,       0.224,     0.22326,     0.22326,     0.22267,     0.22218,       0.222,     0.22142,      0.2185,\n",
            "            0.21778,     0.21769,     0.21769,     0.21769,     0.21699,     0.21382,     0.21163,     0.21074,     0.20992,     0.20542,     0.20249,     0.20007,     0.19868,     0.19868,     0.19379,     0.19067,     0.18924,     0.18858,     0.18696,     0.18265,     0.18205,     0.18185,      0.1812,\n",
            "            0.17931,      0.1788,     0.17805,     0.17628,     0.17574,      0.1731,     0.17223,     0.17112,     0.17107,     0.17067,     0.17032,      0.1683,      0.1683,     0.16745,     0.16485,      0.1645,      0.1645,     0.16414,      0.1631,     0.16086,     0.15788,     0.15749,     0.15645,\n",
            "            0.15645,     0.15575,     0.14863,     0.14862,     0.14825,     0.14793,     0.14631,     0.14498,     0.14273,     0.14273,     0.14151,     0.14097,     0.13923,     0.13727,     0.13366,     0.13314,     0.13307,     0.13056,     0.12865,     0.12795,     0.12774,     0.12731,     0.12652,\n",
            "            0.12571,     0.12505,     0.12357,     0.12308,     0.12099,     0.11914,     0.11731,     0.11679,     0.11679,     0.11642,     0.11595,     0.11532,     0.11486,     0.11461,     0.11461,       0.114,     0.11193,     0.11154,     0.11043,     0.11029,      0.1093,     0.10834,     0.10834,\n",
            "            0.10812,     0.10747,     0.10641,     0.10631,     0.10464,     0.10444,     0.10369,     0.10369,     0.10196,     0.10174,     0.10152,      0.1013,     0.10108,     0.10086,     0.10064,     0.10042,      0.1002,    0.099978,    0.099758,    0.099537,    0.099316,    0.099096,    0.098875,\n",
            "           0.098654,    0.098433,    0.098213,    0.097992,    0.097771,    0.097551,     0.09733,    0.097109,    0.096889,    0.096668,    0.096447,    0.096226,    0.096006,    0.095785,    0.095564,    0.095344,    0.095123,    0.094902,    0.094682,    0.094461,     0.09424,    0.094019,    0.093799,\n",
            "           0.093578,    0.093357,    0.093137,    0.092916,    0.092695,    0.092475,    0.092254,    0.092033,    0.091812,    0.091592,    0.091371,     0.09115,     0.09093,    0.090709,    0.090488,    0.090267,    0.090047,    0.089826,    0.089605,    0.089385,    0.089164,    0.088943,    0.088723,\n",
            "           0.088502,    0.088281,     0.08806,     0.08784,    0.087619,    0.087398,    0.087178,    0.086957,    0.086736,    0.086516,    0.086295,    0.086074,    0.085853,    0.085633,    0.085412,    0.085191,    0.084971,     0.08475,    0.084529,    0.084308,    0.084088,    0.083867,    0.083646,\n",
            "           0.083426,    0.083205,    0.082984,    0.082764,    0.082543,    0.082322,    0.082101,    0.081881,     0.08166,    0.081439,    0.081219,    0.080998,    0.080777,    0.080557,    0.080336,    0.080115,    0.079894,    0.079674,    0.079453,    0.079232,    0.079012,    0.078791,     0.07857,\n",
            "            0.07835,    0.078129,    0.077908,    0.077687,    0.077467,    0.077246,    0.077025,    0.076805,    0.076584,    0.076363,    0.076142,    0.075922,    0.075701,     0.07548,     0.07526,    0.075039,    0.074818,    0.074598,    0.074377,    0.074156,    0.073935,    0.073715,    0.073494,\n",
            "           0.073273,    0.073053,    0.072832,    0.072611,    0.072391,     0.07217,    0.071949,    0.071728,    0.071508,    0.071287,    0.071066,    0.070846,    0.070625,    0.070404,    0.070184,    0.069963,    0.069742,    0.069521,    0.069301,     0.06908,    0.068859,    0.068639,    0.068418,\n",
            "           0.068197,    0.067976,    0.067756,    0.067535,    0.067314,    0.067094,    0.066873,    0.066652,    0.066432,    0.066211,     0.06599,    0.065769,    0.065549,    0.065328,    0.065107,    0.064887,    0.064666,    0.064445,    0.064225,    0.064004,    0.063783,    0.063562,    0.063342,\n",
            "           0.063121,      0.0629,     0.06268,    0.062459,    0.062238,    0.062018,    0.061797,    0.061576,    0.061355,    0.061135,    0.060914,    0.060693,    0.060473,    0.060252,    0.060031,     0.05981,     0.05959,    0.059369,    0.059148,    0.058928,    0.058707,    0.058486,    0.058266,\n",
            "           0.058045,    0.057824,    0.057603,    0.057383,    0.057162,    0.056941,    0.056721,      0.0565,    0.056279,    0.056059,    0.055838,    0.055617,    0.055396,    0.055176,    0.054955,    0.054734,    0.054514,    0.054293,    0.054072,    0.053852,    0.053631,     0.05341,    0.053189,\n",
            "           0.052969,    0.052748,    0.052527,    0.052307,    0.052086,    0.051865,    0.051644,    0.051424,    0.051203,    0.050982,    0.050762,    0.050541,     0.05032,      0.0501,    0.049879,    0.049658,    0.049437,    0.049217,    0.048996,    0.048775,    0.048555,    0.048334,    0.048113,\n",
            "           0.047893,    0.047672,    0.047451,     0.04723,     0.04701,    0.046789,    0.046568,    0.046348,    0.046127,    0.045906,    0.045685,    0.045465,    0.045244,    0.045023,    0.044803,    0.044582,    0.044361,    0.044141,     0.04392,    0.043699,    0.043478,    0.043258,    0.043037,\n",
            "           0.042816,    0.042596,    0.042375,    0.042154,    0.041934,    0.041713,    0.041492,    0.041271,    0.041051,     0.04083,    0.040609,    0.040389,    0.040168,    0.039947,    0.039727,    0.039506,    0.039285,    0.039064,    0.038844,    0.038623,    0.038402,    0.038182,    0.037961,\n",
            "            0.03774,    0.037519,    0.037299,    0.037078,    0.036857,    0.036637,    0.036416,    0.036195,    0.035975,    0.035754,    0.035533,    0.035312,    0.035092,    0.034871,     0.03465,     0.03443,    0.034209,    0.033988,    0.033768,    0.033547,    0.033326,    0.033105,    0.032885,\n",
            "           0.032664,    0.032443,    0.032223,    0.032002,    0.031781,    0.031561,     0.03134,    0.031119,    0.030898,    0.030678,    0.030457,    0.030236,    0.030016,    0.029795,    0.029574,    0.029353,    0.029133,    0.028912,    0.028691,    0.028471,     0.02825,    0.028029,    0.027809,\n",
            "           0.027588,    0.027367,    0.027146,    0.026926,    0.026705,    0.026484,    0.026264,    0.026043,    0.025822,    0.025602,    0.025381,     0.02516,    0.024939,    0.024719,    0.024498,    0.024277,    0.024057,    0.023836,    0.023615,    0.023395,    0.023174,    0.022953,    0.022732,\n",
            "           0.022512,    0.022291,     0.02207,     0.02185,    0.021629,    0.021408,    0.021187,    0.020967,    0.020746,    0.020525,    0.020305,    0.020084,    0.019863,    0.019643,    0.019422,    0.019201,     0.01898,     0.01876,    0.018539,    0.018318,    0.018098,    0.017877,    0.017656,\n",
            "           0.017436,    0.017215,    0.016994,    0.016773,    0.016553,    0.016332,    0.016111,    0.015891,     0.01567,    0.015449,    0.015228,    0.015008,    0.014787,    0.014566,    0.014346,    0.014125,    0.013904,    0.013684,    0.013463,    0.013242,    0.013021,    0.012801,     0.01258,\n",
            "           0.012359,    0.012139,    0.011918,    0.011697,    0.011477,    0.011256,    0.011035,    0.010814,    0.010594,    0.010373,    0.010152,   0.0099316,   0.0097109,   0.0094902,   0.0092695,   0.0090488,   0.0088281,   0.0086074,   0.0083867,    0.008166,   0.0079453,   0.0077246,   0.0075039,\n",
            "          0.0072832,   0.0070625,   0.0068418,   0.0066211,   0.0064004,   0.0061797,    0.005959,   0.0057383,   0.0055176,   0.0052969,   0.0050762,   0.0048555,   0.0046348,   0.0044141,   0.0041934,   0.0039727,   0.0037519,   0.0035312,   0.0033105,   0.0030898,   0.0028691,   0.0026484,   0.0024277,\n",
            "           0.002207,   0.0019863,   0.0017656,   0.0015449,   0.0013242,   0.0011035,  0.00088281,  0.00066211,  0.00044141,   0.0002207,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.17146,      0.1715,     0.21578,     0.24796,     0.26824,     0.28918,     0.29887,     0.30831,     0.31424,     0.31815,     0.32187,      0.3279,     0.33168,      0.3355,     0.33713,      0.3408,     0.33979,     0.34341,     0.34392,     0.34227,     0.34367,      0.3399,     0.33611,\n",
            "             0.3336,     0.33387,     0.33284,     0.33165,     0.33073,     0.33333,     0.33079,      0.3345,     0.33434,     0.33523,     0.33514,     0.33414,     0.33427,     0.33483,     0.33563,     0.33266,     0.33097,     0.32944,     0.32938,      0.3274,     0.32735,     0.32558,     0.32569,\n",
            "             0.3262,     0.32605,     0.32458,     0.32446,     0.32494,     0.32607,     0.32462,     0.32486,     0.32532,     0.32457,     0.32318,     0.32434,     0.32314,     0.32136,     0.31979,     0.31678,     0.31486,      0.3127,     0.31216,     0.31142,     0.31033,     0.30952,     0.30789,\n",
            "             0.3077,     0.30786,     0.30587,     0.30467,     0.30496,     0.30335,     0.30404,      0.3023,     0.30169,     0.30188,     0.30108,     0.30063,     0.29929,     0.29887,     0.29818,     0.29753,     0.29719,     0.29746,     0.29482,     0.29467,     0.29481,     0.29303,     0.29109,\n",
            "            0.29146,     0.28923,     0.28932,     0.28911,     0.28542,     0.28632,     0.28714,     0.28626,     0.28431,     0.28445,     0.28472,     0.28402,     0.28299,     0.28336,     0.28321,     0.28261,     0.28286,     0.28092,     0.28103,     0.28115,     0.28127,     0.28021,     0.27984,\n",
            "            0.27972,     0.27906,      0.2796,     0.27813,     0.27691,     0.27726,     0.27545,     0.27354,     0.27151,     0.27171,     0.27188,     0.27086,     0.27111,     0.27129,     0.27142,     0.27155,     0.27114,     0.26964,      0.2696,     0.26914,     0.26801,     0.26749,     0.26755,\n",
            "            0.26735,     0.26638,     0.26573,     0.26418,     0.26222,     0.26243,     0.26257,     0.26283,     0.26304,     0.26209,     0.26159,     0.26051,     0.25971,      0.2591,     0.25686,     0.25538,     0.25478,     0.25416,     0.25354,     0.25321,     0.25231,     0.25132,     0.25138,\n",
            "            0.25144,     0.24982,     0.24821,     0.24829,     0.24826,     0.24722,     0.24654,     0.24538,     0.24402,     0.24408,     0.24327,     0.24025,     0.23872,     0.23835,     0.23645,     0.23578,       0.233,     0.23108,     0.23082,     0.23036,     0.22991,     0.22949,     0.22907,\n",
            "            0.22766,      0.2272,     0.22674,     0.22671,     0.22682,     0.22574,     0.22458,     0.22406,     0.22349,     0.22006,     0.21911,     0.21917,     0.21919,     0.21806,     0.21811,     0.21817,     0.21814,     0.21702,     0.21663,     0.21624,     0.21605,     0.21499,     0.21534,\n",
            "            0.21411,     0.21343,     0.21305,      0.2131,     0.21315,     0.21208,     0.21219,     0.21238,     0.21187,     0.21135,     0.21154,     0.21108,     0.21055,     0.21002,     0.20973,     0.20983,     0.20989,     0.20991,     0.20992,     0.20994,     0.20996,     0.20998,        0.21,\n",
            "            0.21002,     0.20881,      0.2089,     0.20895,     0.20857,      0.2082,     0.20661,     0.20676,     0.20684,     0.20707,     0.20721,     0.20726,     0.20732,     0.20738,     0.20745,     0.20755,     0.20737,     0.20678,      0.2064,     0.20649,     0.20664,     0.20451,     0.20431,\n",
            "            0.20376,      0.2032,      0.2031,     0.20315,      0.2031,     0.20182,     0.20159,     0.20137,     0.20114,     0.20091,     0.20063,     0.19972,     0.19955,     0.19851,     0.19776,     0.19711,     0.19566,     0.19521,     0.19476,     0.19468,     0.19406,     0.19344,     0.19348,\n",
            "            0.19354,     0.19281,     0.19182,     0.19107,     0.19024,     0.18604,     0.18514,     0.18422,     0.18336,     0.18282,     0.18228,      0.1818,     0.18106,     0.18114,     0.18105,     0.18083,      0.1806,     0.18038,     0.18016,     0.17994,     0.17944,     0.17884,      0.1785,\n",
            "            0.17834,     0.17818,     0.17802,     0.17786,      0.1777,     0.17754,     0.17738,     0.17733,     0.17736,      0.1774,     0.17696,     0.17593,     0.17557,     0.17521,     0.17485,     0.17414,      0.1731,     0.17133,     0.17098,     0.17073,     0.17048,     0.17023,     0.16998,\n",
            "            0.16894,     0.16758,     0.16692,      0.1665,     0.16608,     0.16567,     0.16526,     0.16485,     0.16448,     0.16425,     0.16402,     0.16379,     0.16356,     0.16333,     0.16285,      0.1621,     0.16153,     0.16103,     0.16055,     0.16029,     0.16003,     0.15976,      0.1595,\n",
            "            0.15924,     0.15905,     0.15886,     0.15868,     0.15849,      0.1583,     0.15811,      0.1579,     0.15748,     0.15707,     0.15665,     0.15665,      0.1564,     0.15616,     0.15591,     0.15566,     0.15541,     0.15355,     0.15253,     0.15213,     0.15174,      0.1512,     0.14991,\n",
            "            0.14874,     0.14879,     0.14884,     0.14792,     0.14743,      0.1473,     0.14717,     0.14703,      0.1469,     0.14676,     0.14663,      0.1465,     0.14636,     0.14623,     0.14608,      0.1459,     0.14573,     0.14555,     0.14538,      0.1452,     0.14503,     0.14485,     0.14345,\n",
            "            0.14325,     0.14305,     0.14286,     0.14266,     0.14247,     0.14227,      0.1413,     0.13989,     0.13899,     0.13822,     0.13815,     0.13819,      0.1382,     0.13822,     0.13823,     0.13824,     0.13826,     0.13827,     0.13823,     0.13767,     0.13712,     0.13624,     0.13547,\n",
            "            0.13517,     0.13488,     0.13459,      0.1343,     0.13388,     0.13341,     0.13293,     0.13289,     0.13293,     0.13257,     0.13209,     0.13161,     0.13107,     0.13053,     0.12973,     0.12859,     0.12749,     0.12691,     0.12633,     0.12599,     0.12581,     0.12563,     0.12545,\n",
            "            0.12527,     0.12509,     0.12491,     0.12473,     0.12336,     0.12284,     0.12232,     0.12174,     0.12103,     0.12045,     0.12009,     0.11973,     0.11937,     0.11899,     0.11861,     0.11822,     0.11784,     0.11782,     0.11535,     0.11374,     0.11366,     0.11358,      0.1135,\n",
            "            0.11342,     0.11334,     0.11326,     0.11318,     0.11311,     0.11303,     0.11295,     0.11287,     0.11279,     0.11271,     0.11263,     0.11255,     0.11248,      0.1124,     0.11172,     0.10905,     0.10808,     0.10788,     0.10768,     0.10748,     0.10728,     0.10708,     0.10688,\n",
            "            0.10671,     0.10662,     0.10652,     0.10643,     0.10633,     0.10623,     0.10614,     0.10604,     0.10594,     0.10585,     0.10575,     0.10566,     0.10556,     0.10546,     0.10537,     0.10505,     0.10465,     0.10426,     0.10346,     0.10102,     0.10062,     0.10023,    0.099833,\n",
            "            0.09945,    0.099075,    0.098698,    0.098322,     0.09755,    0.096876,    0.096911,    0.096936,    0.096825,    0.096715,    0.096605,    0.096494,    0.096384,    0.096273,    0.096163,    0.096052,    0.095942,    0.095831,     0.09572,     0.09561,    0.095366,    0.094618,    0.093912,\n",
            "           0.093302,    0.092691,    0.092693,    0.092711,    0.092729,    0.092567,    0.091201,     0.09024,    0.088517,    0.088311,    0.088163,    0.088014,    0.087866,    0.087717,    0.087569,     0.08742,    0.087272,    0.087123,    0.085552,    0.085319,    0.085085,    0.084852,    0.084618,\n",
            "           0.084384,     0.08415,    0.083892,    0.083634,    0.083375,    0.083117,    0.082858,    0.081232,    0.080975,    0.080719,    0.080462,    0.080205,    0.079949,    0.079446,    0.078693,    0.078131,    0.077711,    0.077291,     0.07679,    0.075729,    0.075287,    0.075044,    0.074801,\n",
            "           0.074557,    0.074314,     0.07407,    0.073622,    0.073118,    0.072614,    0.071626,    0.070914,    0.070534,    0.070154,    0.069774,     0.06923,    0.068603,    0.067963,    0.067298,    0.066619,    0.065852,    0.065052,    0.064135,    0.063289,    0.062488,    0.061853,    0.061265,\n",
            "           0.059331,    0.059194,    0.059056,    0.058919,    0.058781,    0.058644,    0.058506,    0.058369,    0.058231,    0.058093,    0.057956,    0.057674,     0.05723,    0.056787,    0.056126,    0.054417,    0.053134,    0.051253,    0.049959,    0.049288,    0.048851,    0.048627,    0.048403,\n",
            "            0.04818,    0.047956,    0.047732,    0.047509,    0.046359,    0.045811,    0.045578,    0.045345,    0.045112,    0.044878,    0.044645,    0.044317,    0.043753,     0.04319,    0.042616,    0.042037,    0.041439,    0.040264,    0.039733,    0.039417,    0.039102,    0.038786,     0.03847,\n",
            "           0.038465,    0.038468,    0.038472,    0.038475,    0.038479,    0.038482,    0.038485,    0.038488,    0.037179,    0.036472,    0.035949,    0.035467,    0.035478,    0.035489,    0.035495,    0.035498,    0.035501,    0.035503,    0.035506,    0.035509,    0.035511,    0.035514,    0.035517,\n",
            "           0.035519,    0.035385,    0.034749,    0.034112,    0.033534,    0.032968,    0.032434,    0.032094,    0.031754,    0.031414,    0.031074,    0.029319,    0.028418,    0.027623,    0.026968,    0.026379,    0.026394,    0.025609,    0.024762,    0.024349,    0.023936,    0.023522,    0.022987,\n",
            "           0.022345,    0.021685,    0.020917,    0.020222,     0.02001,    0.019799,    0.019588,    0.019376,    0.019165,    0.018954,    0.018742,    0.018563,    0.018391,    0.018219,    0.018046,    0.017874,    0.017702,    0.017529,    0.017357,    0.017184,    0.016516,    0.015769,    0.014026,\n",
            "           0.013703,     0.01338,    0.013057,    0.012734,    0.012109,    0.010928,    0.010699,     0.01047,     0.01024,    0.010011,   0.0097817,   0.0095523,   0.0093758,     0.00931,   0.0092442,   0.0091784,   0.0091127,   0.0090469,   0.0089811,   0.0089153,   0.0088495,   0.0087837,   0.0087179,\n",
            "          0.0086521,   0.0085863,   0.0085205,   0.0084546,   0.0083888,    0.008323,   0.0082571,   0.0081913,   0.0081255,   0.0080596,   0.0079938,   0.0079279,    0.007862,   0.0077033,   0.0074876,   0.0072718,   0.0070559,   0.0068401,   0.0066241,   0.0064081,   0.0062575,   0.0062129,   0.0061683,\n",
            "          0.0061237,    0.006079,   0.0060344,   0.0059898,   0.0059452,   0.0059006,   0.0058559,   0.0058113,   0.0057667,    0.005722,   0.0056774,   0.0056328,   0.0055881,   0.0055435,   0.0054988,   0.0054542,   0.0054096,   0.0053649,   0.0053203,   0.0052756,   0.0052309,   0.0051863,   0.0051416,\n",
            "           0.005097,   0.0050523,   0.0050076,    0.004963,   0.0049183,   0.0048736,    0.004829,   0.0047843,   0.0047396,   0.0045913,     0.00423,   0.0038686,   0.0035071,   0.0031455,   0.0031185,   0.0030947,   0.0030708,    0.003047,   0.0030231,   0.0029993,   0.0029754,   0.0029516,   0.0029277,\n",
            "          0.0029038,     0.00288,   0.0028561,   0.0028323,   0.0028084,   0.0027845,   0.0027607,   0.0027368,    0.002713,   0.0026891,   0.0026652,   0.0026414,   0.0026175,   0.0025936,   0.0025698,   0.0025459,    0.002522,   0.0024982,   0.0024743,   0.0024504,   0.0024266,   0.0024027,   0.0023788,\n",
            "          0.0023549,   0.0023311,   0.0023072,   0.0022833,   0.0022595,   0.0022356,   0.0022117,   0.0021878,    0.002164,   0.0021401,   0.0021162,   0.0020923,   0.0020684,   0.0020446,   0.0020207,   0.0019968,   0.0019729,    0.001949,   0.0019252,   0.0019013,   0.0018774,   0.0018535,   0.0018296,\n",
            "          0.0018057,   0.0017819,    0.001758,   0.0017341,   0.0017102,   0.0016863,   0.0016624,   0.0016385,   0.0016146,   0.0015908,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[      0.102,     0.10203,     0.13785,     0.16804,     0.19063,     0.21485,     0.23051,     0.24707,     0.25989,     0.27121,      0.2822,     0.29708,     0.30956,     0.31879,     0.32713,      0.3386,     0.34455,      0.3547,     0.36135,     0.36654,     0.37513,     0.37736,      0.3812,\n",
            "             0.3851,     0.39134,     0.39577,      0.4016,     0.40701,      0.4157,     0.41957,     0.43173,      0.4352,     0.44126,     0.44503,      0.4494,     0.45444,      0.4589,     0.46681,     0.47103,      0.4744,     0.47927,     0.48485,      0.4852,     0.49116,     0.49406,     0.49983,\n",
            "            0.50576,     0.51043,     0.51196,     0.51391,      0.5213,     0.53114,     0.53612,     0.54112,     0.54803,     0.55387,     0.55849,     0.56555,     0.56798,     0.56858,     0.56812,     0.56885,     0.57055,     0.56905,       0.571,     0.57249,     0.57557,     0.57921,     0.57878,\n",
            "            0.58087,     0.58199,     0.58241,     0.58241,     0.58583,     0.58667,     0.59183,     0.59183,     0.59393,     0.59539,     0.59598,      0.5994,     0.60117,     0.60717,     0.60841,     0.61048,     0.61529,     0.61758,     0.61838,     0.61937,     0.62643,     0.62708,     0.62626,\n",
            "            0.63226,     0.63318,     0.63595,     0.63767,     0.63468,     0.64365,     0.65209,     0.65291,      0.6526,     0.65404,     0.65696,     0.65909,     0.65916,     0.66318,     0.66535,     0.66479,     0.66846,     0.66683,     0.66983,     0.67123,     0.67258,     0.67537,     0.67896,\n",
            "             0.6806,     0.68152,     0.69023,     0.68891,     0.69194,     0.69827,     0.69901,     0.70059,     0.70072,     0.70346,     0.70578,     0.70578,     0.70923,     0.71173,     0.71354,     0.71528,      0.7167,      0.7154,     0.71697,     0.71724,     0.71625,     0.71648,     0.71747,\n",
            "            0.71799,     0.71714,     0.71657,     0.71754,     0.71592,     0.71908,     0.72112,     0.72517,     0.72831,     0.73001,     0.73226,     0.73132,     0.73063,      0.7301,     0.72813,     0.72682,     0.72628,     0.72573,     0.72517,     0.72743,     0.72662,     0.72852,     0.72959,\n",
            "            0.73066,     0.72958,     0.73081,     0.73221,     0.73349,     0.73526,     0.73465,      0.7336,     0.73382,     0.73793,      0.7372,     0.73444,     0.73751,     0.73837,     0.73662,     0.73599,     0.73415,     0.74056,      0.7432,     0.74278,     0.74236,     0.74196,     0.74157,\n",
            "            0.74023,     0.73978,     0.73934,     0.74334,     0.74556,      0.7446,     0.74628,     0.74615,     0.74561,     0.74712,     0.75165,     0.75315,     0.75459,     0.75416,      0.7554,     0.75663,     0.76039,     0.75934,     0.75896,     0.75859,     0.76131,     0.76384,     0.77292,\n",
            "            0.77439,     0.77377,     0.77394,     0.77528,     0.77663,     0.77623,     0.78246,     0.79174,      0.7913,     0.79085,     0.79714,     0.79852,     0.80267,     0.80574,     0.81366,     0.81674,     0.81848,     0.81907,     0.81965,     0.82024,     0.82082,     0.82141,     0.82199,\n",
            "            0.82258,     0.82232,     0.82491,      0.8305,     0.83022,     0.82994,     0.82879,     0.83346,     0.83629,     0.84387,     0.84823,     0.85008,     0.85193,     0.85415,     0.85646,     0.85981,     0.86192,     0.86154,     0.86224,      0.8655,     0.87069,     0.87003,     0.87492,\n",
            "            0.87467,     0.87434,      0.8757,     0.87765,     0.87946,     0.87871,     0.87858,     0.87844,     0.87831,     0.87817,     0.87801,     0.87747,     0.88168,     0.88209,     0.88166,     0.88128,     0.88042,     0.88015,     0.87988,     0.88524,     0.88499,     0.88463,     0.88724,\n",
            "            0.88997,     0.88991,     0.88935,     0.89161,     0.89424,     0.89189,     0.89137,     0.89084,     0.89034,     0.89002,      0.8897,     0.89553,     0.89571,     0.89971,     0.90134,     0.90122,      0.9011,     0.90098,     0.90086,     0.90074,     0.90046,     0.90014,     0.89995,\n",
            "            0.89986,     0.89977,     0.89968,     0.89959,      0.8995,     0.89941,     0.89932,     0.90036,     0.90233,     0.90431,     0.90555,       0.905,     0.90481,     0.90461,     0.90442,     0.90403,     0.90346,     0.90248,     0.90905,     0.90891,     0.90878,     0.90865,     0.90852,\n",
            "            0.90796,     0.90722,     0.90685,     0.90662,     0.90639,     0.90616,     0.90593,      0.9057,     0.90549,     0.90536,     0.90523,     0.90509,     0.90496,     0.90483,     0.90456,     0.90412,     0.90379,      0.9035,     0.90321,     0.90306,      0.9029,     0.90274,     0.90259,\n",
            "            0.90243,     0.90232,      0.9022,     0.90209,     0.90197,     0.90186,     0.90174,     0.90162,     0.90136,     0.90111,     0.90085,     0.90829,     0.90815,       0.908,     0.90786,     0.90772,     0.90757,     0.90647,     0.90586,     0.90562,     0.90537,     0.90504,     0.90424,\n",
            "            0.90402,     0.90777,      0.9115,     0.91096,     0.91067,     0.91059,     0.91051,     0.91043,     0.91035,     0.91027,     0.91019,     0.91011,     0.91003,     0.90995,     0.90986,     0.90975,     0.90964,     0.90953,     0.90943,     0.90932,     0.90921,     0.90911,     0.90824,\n",
            "            0.90811,     0.90799,     0.90787,     0.90774,     0.90762,      0.9075,     0.90687,     0.90596,     0.90537,     0.90485,     0.91033,      0.9141,     0.91529,     0.91649,     0.91768,     0.91887,     0.92007,     0.92126,      0.9223,     0.92199,     0.92167,     0.92118,     0.92073,\n",
            "            0.92056,     0.92039,     0.92022,     0.92005,      0.9198,     0.91952,     0.91924,     0.92294,     0.92752,     0.92837,     0.92811,     0.92785,     0.92756,     0.92726,     0.92681,     0.92617,     0.92554,      0.9252,     0.92487,     0.92467,     0.92456,     0.92445,     0.92434,\n",
            "            0.92424,     0.92413,     0.92402,     0.92391,     0.92308,     0.92276,     0.92244,     0.92207,     0.92163,     0.92126,     0.92103,     0.92079,     0.92056,     0.92032,     0.92006,     0.91981,     0.91955,     0.93018,      0.9287,     0.92771,     0.92766,     0.92761,     0.92756,\n",
            "            0.92751,     0.92746,     0.92741,     0.92736,     0.92731,     0.92726,     0.92721,     0.92716,     0.92711,     0.92706,     0.92701,     0.92696,     0.92691,     0.92686,     0.92642,     0.92466,       0.924,     0.92386,     0.92373,     0.92359,     0.92345,     0.92331,     0.92317,\n",
            "            0.92305,     0.92299,     0.92292,     0.92285,     0.92278,     0.92271,     0.92264,     0.92258,     0.92251,     0.92244,     0.92237,      0.9223,     0.92223,     0.92216,      0.9221,     0.92187,     0.92158,     0.92129,      0.9207,     0.91884,     0.91853,     0.91822,     0.91791,\n",
            "             0.9176,      0.9173,       0.917,     0.91669,     0.91606,     0.91652,     0.92273,     0.92857,     0.92849,     0.92841,     0.92832,     0.92824,     0.92816,     0.92808,       0.928,     0.92792,     0.92784,     0.92776,     0.92768,      0.9276,     0.92742,     0.92686,     0.92633,\n",
            "            0.92586,     0.92539,     0.92892,     0.93257,     0.93621,     0.93928,     0.93838,     0.93774,     0.93655,      0.9364,      0.9363,     0.93619,     0.93609,     0.93598,     0.93587,     0.93577,     0.93566,     0.93556,      0.9344,     0.93422,     0.93405,     0.93387,     0.93369,\n",
            "            0.93351,     0.93334,     0.93313,     0.93293,     0.93273,     0.93252,     0.93232,     0.93101,     0.93079,     0.93058,     0.93036,     0.93015,     0.92993,      0.9295,     0.92885,     0.92836,     0.92798,      0.9276,     0.92715,     0.92616,     0.92575,     0.92551,     0.92528,\n",
            "            0.92505,     0.92481,     0.92458,     0.92413,     0.92363,     0.92313,     0.92211,     0.92136,     0.92096,     0.92055,     0.92014,     0.91954,     0.91884,     0.91811,     0.91734,     0.91655,     0.91562,     0.91464,     0.91349,      0.9124,     0.91134,     0.91048,     0.90968,\n",
            "            0.90693,     0.90673,     0.90652,     0.90631,     0.90611,      0.9059,      0.9057,     0.90549,     0.90528,     0.90508,     0.90487,     0.90443,     0.90374,     0.90304,     0.90198,     0.89913,     0.89689,     0.89341,     0.89089,     0.88954,     0.88864,     0.88817,     0.88769,\n",
            "            0.88722,     0.88674,     0.88626,     0.88579,     0.88321,     0.88196,      0.8814,     0.88085,     0.88029,     0.87974,     0.87918,     0.87838,     0.87696,     0.87553,     0.87403,     0.87247,     0.87087,     0.86751,     0.86595,     0.86498,     0.86402,     0.86306,     0.86209,\n",
            "            0.86548,     0.86897,     0.87247,     0.87597,     0.87947,     0.88297,     0.88647,     0.88997,     0.88941,     0.88745,     0.88598,     0.88566,      0.8995,     0.91335,     0.92193,     0.92565,     0.92937,     0.93309,     0.93681,     0.94053,     0.94425,     0.94797,     0.95169,\n",
            "            0.95541,     0.95817,     0.95741,     0.95665,     0.95591,     0.95518,     0.95448,     0.95399,     0.95351,     0.95303,     0.95254,      0.9498,     0.94825,     0.94683,     0.94557,     0.94865,     0.99135,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.53737,     0.53737,     0.49646,     0.47286,      0.4524,     0.44217,     0.42486,     0.40991,     0.39732,     0.38474,     0.37451,     0.36585,      0.3572,     0.35405,     0.34776,     0.34304,     0.33517,     0.33281,     0.32809,     0.32101,     0.31707,     0.30921,     0.30055,\n",
            "            0.29426,     0.29111,     0.28718,     0.28245,     0.27852,      0.2782,     0.27301,     0.27301,     0.27144,     0.27029,     0.26877,     0.26593,     0.26436,     0.26357,       0.262,     0.25713,     0.25413,     0.25098,     0.24941,     0.24705,     0.24548,     0.24279,     0.24154,\n",
            "            0.24073,     0.23953,     0.23761,     0.23707,     0.23603,     0.23525,     0.23278,      0.2321,     0.23131,     0.22955,     0.22738,     0.22737,     0.22581,     0.22397,     0.22253,     0.21951,     0.21742,     0.21558,     0.21479,     0.21388,     0.21243,     0.21119,     0.20973,\n",
            "            0.20928,     0.20928,     0.20739,      0.2063,     0.20614,     0.20456,     0.20456,     0.20299,      0.2022,      0.2022,     0.20142,     0.20063,     0.19924,     0.19822,     0.19748,      0.1967,     0.19591,     0.19591,     0.19355,     0.19332,     0.19276,     0.19119,     0.18961,\n",
            "            0.18938,     0.18742,     0.18725,     0.18693,     0.18411,     0.18411,     0.18411,     0.18332,     0.18175,     0.18175,     0.18175,     0.18101,     0.18017,     0.18017,     0.17989,     0.17944,     0.17939,     0.17794,     0.17781,     0.17781,     0.17781,     0.17678,     0.17624,\n",
            "            0.17604,     0.17545,     0.17531,     0.17423,     0.17309,     0.17297,     0.17152,     0.16994,     0.16837,     0.16837,     0.16837,     0.16758,     0.16758,     0.16758,     0.16758,     0.16758,     0.16719,     0.16613,     0.16601,     0.16565,     0.16484,     0.16444,     0.16444,\n",
            "            0.16426,     0.16357,     0.16311,     0.16189,      0.1605,      0.1605,      0.1605,      0.1605,      0.1605,     0.15972,     0.15924,     0.15848,     0.15792,      0.1575,     0.15593,      0.1549,     0.15448,     0.15406,     0.15362,     0.15329,     0.15266,     0.15185,     0.15185,\n",
            "            0.15185,     0.15071,     0.14949,     0.14949,     0.14941,     0.14859,     0.14813,     0.14733,     0.14634,     0.14622,     0.14567,     0.14361,     0.14241,     0.14211,     0.14083,     0.14038,     0.13847,      0.1369,     0.13662,     0.13632,     0.13602,     0.13574,     0.13546,\n",
            "            0.13452,     0.13421,      0.1339,     0.13375,     0.13375,     0.13304,     0.13218,     0.13182,     0.13144,     0.12903,     0.12825,     0.12825,     0.12822,     0.12746,     0.12746,     0.12746,     0.12734,      0.1266,     0.12635,     0.12609,     0.12589,      0.1251,      0.1251,\n",
            "            0.12423,     0.12379,     0.12352,     0.12352,     0.12352,     0.12282,     0.12274,     0.12264,     0.12231,     0.12198,     0.12195,     0.12161,     0.12116,     0.12075,     0.12038,     0.12038,     0.12038,     0.12038,     0.12038,     0.12038,     0.12038,     0.12038,     0.12038,\n",
            "            0.12038,     0.11959,     0.11959,     0.11951,     0.11927,     0.11903,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11802,     0.11787,     0.11749,     0.11723,     0.11723,     0.11723,     0.11587,     0.11566,\n",
            "            0.11531,     0.11496,     0.11487,     0.11487,      0.1148,       0.114,     0.11386,     0.11372,     0.11357,     0.11343,     0.11326,     0.11269,     0.11251,     0.11184,     0.11137,     0.11096,     0.11006,     0.10978,      0.1095,     0.10936,     0.10898,     0.10859,     0.10858,\n",
            "            0.10858,     0.10811,      0.1075,       0.107,     0.10644,     0.10385,      0.1033,     0.10273,     0.10221,     0.10187,     0.10154,     0.10117,     0.10071,     0.10071,     0.10063,     0.10049,     0.10036,     0.10022,     0.10009,    0.099954,    0.099646,    0.099285,    0.099077,\n",
            "            0.09898,    0.098882,    0.098784,    0.098686,    0.098588,     0.09849,    0.098392,    0.098348,    0.098348,    0.098348,    0.098061,    0.097437,    0.097219,    0.097001,    0.096782,    0.096351,    0.095722,    0.094652,    0.094364,    0.094213,    0.094062,    0.093912,    0.093761,\n",
            "           0.093137,    0.092319,    0.091921,    0.091668,    0.091416,    0.091167,    0.090923,     0.09068,    0.090455,    0.090317,    0.090179,    0.090041,    0.089904,    0.089766,    0.089481,    0.089032,    0.088692,    0.088394,    0.088107,    0.087951,    0.087794,    0.087637,     0.08748,\n",
            "           0.087326,    0.087214,    0.087101,    0.086988,    0.086875,    0.086763,     0.08665,    0.086527,    0.086279,    0.086032,    0.085785,    0.085719,    0.085571,    0.085423,    0.085276,    0.085128,    0.084981,    0.083881,    0.083276,    0.083042,    0.082808,     0.08249,    0.081728,\n",
            "           0.081039,    0.081039,    0.081038,    0.080496,    0.080209,     0.08013,    0.080052,    0.079974,    0.079895,    0.079817,    0.079738,     0.07966,    0.079582,    0.079503,    0.079412,     0.07931,    0.079207,    0.079105,    0.079002,      0.0789,    0.078797,    0.078695,    0.077872,\n",
            "           0.077758,    0.077644,    0.077529,    0.077415,    0.077301,    0.077187,     0.07662,    0.075799,    0.075273,    0.074824,    0.074744,    0.074744,    0.074744,    0.074744,    0.074744,    0.074744,    0.074744,    0.074744,    0.074711,    0.074389,    0.074067,    0.073561,    0.073111,\n",
            "           0.072942,    0.072773,    0.072604,    0.072435,    0.072194,     0.07192,    0.071647,    0.071597,    0.071597,    0.071384,    0.071107,     0.07083,    0.070519,    0.070206,    0.069746,    0.069091,    0.068459,    0.068125,    0.067795,    0.067601,    0.067498,    0.067394,    0.067291,\n",
            "           0.067187,    0.067084,     0.06698,    0.066877,    0.066097,    0.065797,    0.065501,     0.06517,    0.064766,    0.064438,    0.064232,    0.064027,    0.063822,    0.063609,     0.06339,    0.063171,    0.062952,    0.062894,    0.061492,    0.060582,    0.060537,    0.060493,    0.060448,\n",
            "           0.060404,    0.060359,    0.060315,     0.06027,    0.060226,    0.060181,    0.060137,    0.060092,    0.060048,    0.060004,    0.059959,    0.059915,     0.05987,    0.059826,    0.059442,     0.05794,    0.057396,    0.057284,    0.057172,     0.05706,    0.056948,    0.056835,    0.056723,\n",
            "            0.05663,    0.056576,    0.056523,    0.056469,    0.056415,    0.056361,    0.056307,    0.056253,    0.056199,    0.056145,    0.056092,    0.056038,    0.055984,     0.05593,    0.055876,      0.0557,    0.055477,    0.055255,    0.054811,    0.053448,    0.053228,    0.053008,    0.052787,\n",
            "           0.052574,    0.052365,    0.052156,    0.051947,    0.051518,    0.051141,    0.051141,    0.051137,    0.051076,    0.051015,    0.050953,    0.050892,    0.050831,     0.05077,    0.050709,    0.050647,    0.050586,    0.050525,    0.050464,    0.050402,    0.050268,    0.049853,    0.049463,\n",
            "           0.049126,    0.048789,     0.04878,     0.04878,     0.04878,    0.048682,     0.04793,    0.047401,    0.046454,    0.046341,    0.046259,    0.046178,    0.046096,    0.046015,    0.045933,    0.045852,     0.04577,    0.045689,    0.044828,    0.044701,    0.044573,    0.044445,    0.044317,\n",
            "           0.044189,    0.044062,     0.04392,    0.043779,    0.043638,    0.043497,    0.043356,    0.042469,    0.042329,    0.042189,    0.042049,     0.04191,     0.04177,    0.041497,    0.041087,    0.040782,    0.040554,    0.040325,    0.040054,    0.039478,    0.039239,    0.039108,    0.038976,\n",
            "           0.038844,    0.038712,    0.038581,    0.038338,    0.038066,    0.037793,     0.03726,    0.036876,    0.036671,    0.036467,    0.036262,    0.035969,    0.035632,    0.035288,     0.03493,    0.034566,    0.034154,    0.033726,    0.033234,    0.032781,    0.032353,    0.032014,      0.0317,\n",
            "           0.030669,    0.030596,    0.030522,    0.030449,    0.030376,    0.030303,    0.030229,    0.030156,    0.030083,     0.03001,    0.029937,    0.029787,    0.029551,    0.029315,    0.028964,    0.028058,    0.027378,    0.026383,      0.0257,    0.025346,    0.025116,    0.024998,     0.02488,\n",
            "           0.024762,    0.024644,    0.024527,    0.024409,    0.023804,    0.023516,    0.023394,    0.023271,    0.023149,    0.023026,    0.022904,    0.022732,    0.022436,    0.022141,    0.021841,    0.021537,    0.021224,     0.02061,    0.020333,    0.020168,    0.020003,    0.019839,    0.019674,\n",
            "            0.01967,     0.01967,     0.01967,     0.01967,     0.01967,     0.01967,     0.01967,     0.01967,    0.018987,    0.018618,    0.018347,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,    0.018096,\n",
            "           0.018096,    0.018026,    0.017695,    0.017365,    0.017066,    0.016774,    0.016497,    0.016322,    0.016146,     0.01597,    0.015795,    0.014889,    0.014425,    0.014016,    0.013679,    0.013375,    0.013375,     0.01297,    0.012536,    0.012324,    0.012113,    0.011901,    0.011627,\n",
            "           0.011299,    0.010961,    0.010569,    0.010214,    0.010106,   0.0099985,   0.0098908,    0.009783,   0.0096753,   0.0095675,   0.0094597,   0.0093686,   0.0092808,   0.0091931,   0.0091053,   0.0090176,   0.0089298,   0.0088421,   0.0087543,   0.0086666,   0.0083268,   0.0079473,   0.0070627,\n",
            "           0.006899,   0.0067352,   0.0065714,   0.0064077,   0.0060913,    0.005494,   0.0053782,   0.0052624,   0.0051465,   0.0050307,   0.0049149,   0.0047991,     0.00471,   0.0046768,   0.0046436,   0.0046104,   0.0045772,    0.004544,   0.0045108,   0.0044776,   0.0044444,   0.0044112,    0.004378,\n",
            "          0.0043448,   0.0043117,   0.0042785,   0.0042453,   0.0042121,   0.0041789,   0.0041457,   0.0041125,   0.0040793,   0.0040461,   0.0040129,   0.0039797,   0.0039465,   0.0038666,   0.0037579,   0.0036492,   0.0035405,   0.0034318,   0.0033231,   0.0032144,   0.0031386,   0.0031161,   0.0030937,\n",
            "          0.0030712,   0.0030488,   0.0030263,   0.0030039,   0.0029815,    0.002959,   0.0029366,   0.0029141,   0.0028917,   0.0028692,   0.0028468,   0.0028243,   0.0028019,   0.0027794,    0.002757,   0.0027346,   0.0027121,   0.0026897,   0.0026672,   0.0026448,   0.0026223,   0.0025999,   0.0025774,\n",
            "           0.002555,   0.0025326,   0.0025101,   0.0024877,   0.0024652,   0.0024428,   0.0024203,   0.0023979,   0.0023754,   0.0023009,   0.0021195,   0.0019381,   0.0017566,   0.0015752,   0.0015617,   0.0015497,   0.0015378,   0.0015258,   0.0015139,   0.0015019,   0.0014899,    0.001478,    0.001466,\n",
            "           0.001454,   0.0014421,   0.0014301,   0.0014181,   0.0014062,   0.0013942,   0.0013822,   0.0013703,   0.0013583,   0.0013464,   0.0013344,   0.0013224,   0.0013105,   0.0012985,   0.0012865,   0.0012746,   0.0012626,   0.0012506,   0.0012387,   0.0012267,   0.0012148,   0.0012028,   0.0011908,\n",
            "          0.0011789,   0.0011669,   0.0011549,    0.001143,    0.001131,    0.001119,   0.0011071,   0.0010951,   0.0010831,   0.0010712,   0.0010592,   0.0010473,   0.0010353,   0.0010233,   0.0010114,   0.0009994,  0.00098744,  0.00097547,  0.00096351,  0.00095154,  0.00093958,  0.00092762,  0.00091565,\n",
            "         0.00090369,  0.00089172,  0.00087976,   0.0008678,  0.00085583,  0.00084387,   0.0008319,  0.00081994,  0.00080797,  0.00079601,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: np.float64(0.14507869413948393)\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,\n",
            "           0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,\n",
            "           0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,\n",
            "           0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824,     0.12824])\n",
            "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
            "nt_per_class: array([1271,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
            "nt_per_image: array([423,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "results_dict: {'metrics/precision(B)': np.float64(0.553869717081451), 'metrics/recall(B)': np.float64(0.2295454854258245), 'metrics/mAP50(B)': np.float64(0.2965833526663716), 'metrics/mAP50-95(B)': np.float64(0.12824484319205198), 'fitness': np.float64(0.14507869413948393)}\n",
            "save_dir: PosixPath('runs/detect/val3')\n",
            "speed: {'preprocess': 0.36065877131914587, 'inference': 1.4569600542602903, 'loss': 0.004073963180050578, 'postprocess': 1.2599310697678519}\n",
            "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
            "task: 'detect'\n"
          ]
        }
      ],
      "source": [
        "# Evaluates the trained model using the TEST SET defined in data.yaml\n",
        "\n",
        "metrics_YOLOv11n = model_YOLOv11n.val(data='data.yaml', split='test') # returns accuracy metrics (e.g., mAP, precision, recall, etc.) on the test set\n",
        "print(\"Test metrics:\", metrics_YOLOv11n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meN-A5gNxGLR",
        "outputId": "f927b62e-7b48-4230-f8eb-95503be7234d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#  Inference (practical use of the fine-tuned model)\n",
        "\n",
        "# Load the best weights found\n",
        "best_YOLOv11n = '/content/runs_finetune/person_yolov11n/weights/best_yolov11n.pt'\n",
        "model_inf_YOLOv11n = YOLO(best_YOLOv11n) # Creates a new model instance by loading the best weights\n",
        "\n",
        "# Performs inference on one or more images, or on a video, by specifying the path in the source parameter.\n",
        "# conf=0.25 → Confidence threshold for considering a detection valid.\n",
        "preds_YOLOv11n = model_inf_YOLOv11n.predict(\n",
        "  # source='/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/test/images',\n",
        "  source='/content/AERALIS_YOLOv11n_local/test/images',\n",
        "  conf=0.25,\n",
        "  verbose=False, # disable on-screen printing\n",
        "  save=True\n",
        ")\n",
        "\n",
        "# Too many images to show!\n",
        "# for result in preds_YOLOv8n:\n",
        "#    result.show() # displays the predictions (eventually you can also save them)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvBabxqEwNoZ"
      },
      "outputs": [],
      "source": [
        "# Create folders on Google Drive (first time only):\n",
        "!mkdir -p /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/results/annotated\n",
        "!mkdir -p /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IcdPypVwNlS"
      },
      "outputs": [],
      "source": [
        "# Copy annotated images:\n",
        "!cp -r /content/runs/detect/predict/* /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/results/annotated/\n",
        "\n",
        "# Copy the best weights (best.pt) after training:\n",
        "!cp /content/runs_finetune/person_yolov11n/weights/best_yolov11n.pt /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ_G1zHIwNh5"
      },
      "outputs": [],
      "source": [
        "# To download it directly to the computer:\n",
        "from google.colab import files\n",
        "files.download('/content/runs_finetune/person_yolov11n/weights/best_yolov11n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuIAUf12wNe3"
      },
      "outputs": [],
      "source": [
        "# Path of saved weights:\n",
        "weights_path_YOLOv11n = '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.pt'\n",
        "model_YOLOv11n = YOLO(weights_path_YOLOv11n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvfscJcCwNYK"
      },
      "outputs": [],
      "source": [
        "# Directory of annotated images\n",
        "annotated_dir = '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/results/annotated'\n",
        "\n",
        "# Get all the .jpg files in the directory\n",
        "annotated_imgs_YOLOv11n = [\n",
        "    os.path.join(annotated_dir, f)\n",
        "    for f in os.listdir(annotated_dir)\n",
        "    if f.lower().endswith('.jpg')\n",
        "]\n",
        "\n",
        "# View the first 5 annotated images\n",
        "for img_path in annotated_imgs_YOLOv11n[:5]:\n",
        "  img = Image.open(img_path)\n",
        "  img.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "vIMWPb-ML53e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save metrics YOLOv8n\n",
        "with open(\"metrics_yolov8n.txt\", \"w\") as f:\n",
        "  f.write(str(metrics_YOLOv8n))\n",
        "\n",
        "# Save metrics YOLOv11n\n",
        "with open(\"metrics_yolov11n.txt\", \"w\") as f:\n",
        "  f.write(str(metrics_YOLOv11n))"
      ],
      "metadata": {
        "id": "Szo6kg0OL89b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now view the metrics of the two models and compare them:"
      ],
      "metadata": {
        "id": "rsaME7KnPXAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find the **mean precision** with _.mp()_ and the **mean recall** with _.mr()_ so that we can then calculate the **F1-score**:"
      ],
      "metadata": {
        "id": "TSjn812pA_dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean precision and recall\n",
        "precision_v8n = metrics_YOLOv8n.box.mp\n",
        "recall_v8n = metrics_YOLOv8n.box.mr\n",
        "precision_v11n = metrics_YOLOv11n.box.mp\n",
        "recall_v11n = metrics_YOLOv11n.box.mr\n",
        "\n",
        "# F1 score calculation\n",
        "f1_yolov8n = 2 * (precision_v8n * recall_v8n) / (precision_v8n + recall_v8n + 1e-6)\n",
        "f1_yolov11n = 2 * (precision_v11n * recall_v11n) / (precision_v11n + recall_v11n + 1e-6)"
      ],
      "metadata": {
        "id": "9-R8JHkdBC5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visually compare the performance of the two fine-tuned models (YOLOv8n and YOLOv11n) on the test set, we extract their main evaluation metrics including mAP@ 0.5, mAP@ 0.5:0.95, Precision, Recall, and F1-score, and generate a comparative bar plot. \\\n",
        "This helps in quickly identifying which model performs better across different criteria."
      ],
      "metadata": {
        "id": "v1DGmjOi-jDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction of key metrics from both models\n",
        "metrics = {\n",
        "  'YOLOv8n': {\n",
        "    'mAP@0.5': metrics_YOLOv8n.box.map50,\n",
        "    'mAP@0.5:0.95': metrics_YOLOv8n.box.map,\n",
        "    'Precision': metrics_YOLOv8n.box.mp,\n",
        "    'Recall': metrics_YOLOv8n.box.mr,\n",
        "    'F1-score': f1_yolov8n\n",
        "  },\n",
        "  'YOLOv11n': {\n",
        "    'mAP@0.5': metrics_YOLOv11n.box.map50,\n",
        "    'mAP@0.5:0.95': metrics_YOLOv11n.box.map,\n",
        "    'Precision': metrics_YOLOv11n.box.mp,\n",
        "    'Recall': metrics_YOLOv11n.box.mr,\n",
        "    'F1-score': f1_yolov11n\n",
        "  }\n",
        "}\n",
        "\n",
        "# Labels and values\n",
        "labels = list(metrics['YOLOv8n'].keys())\n",
        "y8n = [metrics['YOLOv8n'][k] for k in labels]\n",
        "y11n = [metrics['YOLOv11n'][k] for k in labels]\n",
        "\n",
        "# Bar Plot\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars1 = ax.bar(x - width/2, y8n, width, label='YOLOv8n')\n",
        "bars2 = ax.bar(x + width/2, y11n, width, label='YOLOv11n')\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Performance Comparison (Test Set)')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "ax.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "# Notes above the bars\n",
        "for bar in bars1 + bars2:\n",
        "  yval = bar.get_height()\n",
        "  ax.text(bar.get_x() + bar.get_width() / 2.0, yval + 0.01, f'{yval:.2f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "NQPmzvvgPV3v",
        "outputId": "31550fb5-57a7-4959-d72e-67d423c5c7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison plot shows that YOLOv11n slightly outperforms YOLOv8n in all key metrics. Specifically, it achieves higher values in Precision (0.55 vs 0.51), Recall (0.23 vs 0.22), and F1-score (0.32 vs 0.31). The improvement in mAP @0.5 is also evident (0.30 vs 0.27), while mAP @0.5:0.95 remains nearly the same for both models (0.13). These results suggest that YOLOv11n provides a small but consistent advantage in detection performance on the test set."
      ],
      "metadata": {
        "id": "LG4hzmmKFn-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing models for Jetson Nano"
      ],
      "metadata": {
        "id": "BPMsfVMQK5a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will prepare the models best_yolov8n.pt and best_yolov11n.pt so that they can be used on the Jetson Nano. \\\n",
        "Let's clarify a few things:"
      ],
      "metadata": {
        "id": "u9ADl15ZK-Xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ONNX** (*Open Neural Network Exchange*) \\\n",
        "ONNX is a universal deep learning model format that allows exporting models from PyTorch, TensorFlow, Keras, and others. \\\n",
        "It enables running models across different platforms using specialized inference tools.\n",
        "\n",
        "It is an intermediate format: it is not meant for direct inference, but to transfer the model to an optimized inference engine."
      ],
      "metadata": {
        "id": "0lX8B0uXMkKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorRT** (*NVIDIA AI Accelerator*) \\\n",
        "TensorRT is an optimized inference library by NVIDIA, designed specifically for GPUs and Jetson devices. It is significantly faster than PyTorch or TensorFlow for inference and works best with models converted to _.engine_ format (derived from _.onnx_).\n",
        "\n",
        "It uses techniques such as:\n",
        "- Reduced precision (FP16, INT8)\n",
        "- Layer fusion\n",
        "- Runtime optimization\n",
        "\n",
        "It is designed to maximize performance on Jetson devices like the Jetson Nano."
      ],
      "metadata": {
        "id": "PKxs810bM-hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we export to .onnx directly on Colab. If there are compatibility or library issues, we will use a different approach and export _.onnx_ directly on Jetson."
      ],
      "metadata": {
        "id": "IC7vt0eAcHBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders on Google Drive (first time only):\n",
        "!mkdir -p /content/drive/MyDrive/projectUPV/exported_models"
      ],
      "metadata": {
        "id": "aN8-mdqsejxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save directory on Google Drive\n",
        "drive_export_dir = \"/content/drive/MyDrive/projectUPV/exported_models\"\n",
        "os.makedirs(drive_export_dir, exist_ok=True)\n",
        "\n",
        "# List of models to export\n",
        "models_to_export = [\n",
        "  {\"name\": \"YOLOv8n\", \"pt_path\": \"/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.pt\"},\n",
        "  {\"name\": \"YOLOv11n\", \"pt_path\": \"/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.pt\"},\n",
        "]\n",
        "\n",
        "# Export and save loop\n",
        "for model_info in models_to_export:\n",
        "  name = model_info[\"name\"]\n",
        "  pt_path = model_info[\"pt_path\"]\n",
        "\n",
        "  print(f\"Exporting {name} from {pt_path}...\")\n",
        "\n",
        "  # Load the template\n",
        "  model = YOLO(pt_path)\n",
        "\n",
        "  # Export to ONNX\n",
        "  exported = model.export(format=\"onnx\", opset=12, dynamic=False)\n",
        "  onnx_path = exported\n",
        "  print(f\"Exported ONNX file: {onnx_path}\")\n",
        "\n",
        "  # Build destination name\n",
        "  model_name_noext = os.path.splitext(os.path.basename(onnx_path))[0]\n",
        "  drive_dst = os.path.join(drive_export_dir, f\"{model_name_noext}.onnx\")\n",
        "\n",
        "  # Copy to Drive\n",
        "  shutil.copy(onnx_path, drive_dst)\n",
        "  print(f\"{name} saved to Drive: {drive_dst}\\n\")"
      ],
      "metadata": {
        "id": "Z9h39MANd9YZ",
        "outputId": "09ebe979-4bfc-498a-96e5-a10b1c54c769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting YOLOv8n from /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.pt...\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.3s, saved as '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.onnx' (11.6 MB)\n",
            "\n",
            "Export complete (2.6s)\n",
            "Results saved to \u001b[1m/content/drive/.shortcut-targets-by-id/1LQbD7p_iS5KLqGNdfrYEvsAx0i_bgB0h/projectUPV/datasets/AERALIS_YOLOv8n/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.onnx imgsz=640 data=data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Exported ONNX file: /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv8n/weights/best_yolov8n.onnx\n",
            "YOLOv8n saved to Drive: /content/drive/MyDrive/projectUPV/exported_models/best_yolov8n.onnx\n",
            "\n",
            "Exporting YOLOv11n from /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.pt...\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.5s, saved as '/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.onnx' (10.0 MB)\n",
            "\n",
            "Export complete (2.9s)\n",
            "Results saved to \u001b[1m/content/drive/.shortcut-targets-by-id/1LQbD7p_iS5KLqGNdfrYEvsAx0i_bgB0h/projectUPV/datasets/AERALIS_YOLOv11n/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.onnx imgsz=640 data=data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Exported ONNX file: /content/drive/MyDrive/projectUPV/datasets/AERALIS_YOLOv11n/weights/best_yolov11n.onnx\n",
            "YOLOv11n saved to Drive: /content/drive/MyDrive/projectUPV/exported_models/best_yolov11n.onnx\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**trtexec** is a command line tool included in TensorRT. It is used to:\n",
        "- Convert _.onnx_ models into optimized _.engine_ models (TensorRT format)\n",
        "- Perform benchmarks (performance tests) on _.engine_ models"
      ],
      "metadata": {
        "id": "ZCOA3ckmY-1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantization** \\\n",
        "Quantization is a technique that reduces the numerical precision of a model's weights and activations. By reducing precision:\n",
        "- the model takes up less memory (RAM and VRAM)\n",
        "- the model runs faster\n",
        "- but it may lose some accuracy (usually minimal)\n",
        "\n",
        "The Jetson Nano natively supports FP16 via GPU (CUDA), which allows you to speed up the model on the Jetson Nano and save memory."
      ],
      "metadata": {
        "id": "yXaw0Pvd7ud9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now transfer the test set and the two models converted to .onnx to Jetson Nano in order to check performance.\n",
        "Next, we will convert these models from .onnx to .engine using the command:"
      ],
      "metadata": {
        "id": "lbWsdg3BfATf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/src/tensorrt/bin/trtexec --onnx=best_yolov8n.onnx --saveEngine=best_yolov8n.engine --fp16\n",
        "# /usr/src/tensorrt/bin/trtexec --onnx=best_yolov11n.onnx --saveEngine=best_yolov11n.engine --fp16\n",
        "\n",
        "# Nel caso il Jetson non supportasse --fp16, rimuovi --fp16 oppure sostituiscilo con --int8"
      ],
      "metadata": {
        "id": "H2oUwfjye98e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then apply:"
      ],
      "metadata": {
        "id": "qaQ4cid4tL80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trtexec --loadEngine=best_yolov8n.engine --batch=1\n",
        "# trtexec --loadEngine=best_yolov11n.engine --batch=1"
      ],
      "metadata": {
        "id": "Uf_9_CUvtElz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to perform a synthetic benchmark test, which immediately gives you:\n",
        "\n",
        "- Average and maximum latency\n",
        "- FPS (frames per second)\n",
        "- Throughput\n",
        "\n",
        "It does not perform inference on real images but only serves to verify the raw speed of the TensorRT engine."
      ],
      "metadata": {
        "id": "xeGkX7GZtRHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain the output shape from the .onnx models:"
      ],
      "metadata": {
        "id": "LIPYeJBT2DVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "id": "X9w8Pzk82KlM",
        "outputId": "3da9c0d0-f503-4ec9-e433-6788948efc92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx"
      ],
      "metadata": {
        "id": "_K3KfXKx2Mf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the .onnx file\n",
        "\n",
        "model_path_yolov8n = \"/content/drive/MyDrive/projectUPV/exported_models/best_yolov8n.onnx\"\n",
        "model_path_yolov11n = \"/content/drive/MyDrive/projectUPV/exported_models/best_yolov11n.onnx\"\n",
        "onnx_model_yolov8n = onnx.load(model_path_yolov8n)\n",
        "onnx_model_yolov11n = onnx.load(model_path_yolov11n)\n",
        "\n",
        "# Extract info on outputs\n",
        "output_info_yolov8n = onnx_model_yolov8n.graph.output\n",
        "print(\"YOLOv8n \\n\")\n",
        "for out in output_info_yolov8n:\n",
        "  name = out.name\n",
        "  shape = [dim.dim_value for dim in out.type.tensor_type.shape.dim]\n",
        "  print(f\"Output name: {name}, shape: {shape}\")\n",
        "\n",
        "\n",
        "output_info_yolov11n = onnx_model_yolov11n.graph.output\n",
        "print(\"YOLOv11n \\n\")\n",
        "for out in output_info_yolov11n:\n",
        "  name = out.name\n",
        "  shape = [dim.dim_value for dim in out.type.tensor_type.shape.dim]\n",
        "  print(f\"Output name: {name}, shape: {shape}\")"
      ],
      "metadata": {
        "id": "YlK4tTbbt2Tq",
        "outputId": "92264fc1-a0a2-4eac-dd2a-a77c6943ab20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n \n",
            "\n",
            "Output name: output0, shape: [1, 5, 8400]\n",
            "YOLOv11n \n",
            "\n",
            "Output name: output0, shape: [1, 5, 8400]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that the exported ONNX has dynamic shapes (batch, num_detections, elements)."
      ],
      "metadata": {
        "id": "orFmc6Y43yVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script to run on Jetson to run the model on the test set:"
      ],
      "metadata": {
        "id": "xqVmo6eW9fDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "\n",
        "# Config\n",
        "ENGINE_PATH = \"best_yolov8n.engine\"\n",
        "IMG_DIR = \"test/images\"\n",
        "OUT_IMG_DIR = \"results/inference_annotated\"\n",
        "OUT_TXT_DIR = \"results/inference_txt\"\n",
        "CONF_THRESH = 0.25\n",
        "INPUT_H, INPUT_W = 640, 640\n",
        "\n",
        "os.makedirs(OUT_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_TXT_DIR, exist_ok=True)\n",
        "\n",
        "# Preprocess\n",
        "def preprocess(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  orig = img.copy()\n",
        "  h0, w0 = img.shape[:2]\n",
        "\n",
        "  # Calculate scales and padding\n",
        "  r = min(INPUT_W / w0, INPUT_H / h0)\n",
        "  new_w, new_h = int(w0 * r), int(h0 * r)\n",
        "  resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # Create canvas and paste resized image\n",
        "  canvas = np.full((INPUT_H, INPUT_W, 3), 114, dtype=np.uint8)\n",
        "  top = (INPUT_H - new_h) // 2\n",
        "  left = (INPUT_W - new_w) // 2\n",
        "  canvas[top:top + new_h, left:left + new_w] = resized\n",
        "\n",
        "  # Normalize and prepare\n",
        "  img_rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
        "  img_norm = img_rgb.astype(np.float32) / 255.0\n",
        "  img_trans = np.transpose(img_norm, (2, 0, 1))\n",
        "  img_final = np.expand_dims(img_trans, axis=0)\n",
        "\n",
        "  return img_final, orig, (h0, w0), r, top, left\n",
        "\n",
        "\n",
        "# Postprocess\n",
        "def postprocess(output, orig_shape, r, top, left):\n",
        "  h0, w0 = orig_shape\n",
        "  output = output.reshape(5, -1)\n",
        "  boxes = []\n",
        "  for i in range(output.shape[1]):\n",
        "    x, y, w, h, conf = output[:, i]\n",
        "    if conf < CONF_THRESH:\n",
        "      continue\n",
        "    x1 = int((x - w / 2) - left)\n",
        "    y1 = int((y - h / 2) - top)\n",
        "    x2 = int((x + w / 2) - left)\n",
        "    y2 = int((y + h / 2) - top)\n",
        "\n",
        "    # Descale compared to the original image\n",
        "    x1 = int(x1 / r)\n",
        "    x2 = int(x2 / r)\n",
        "    y1 = int(y1 / r)\n",
        "    y2 = int(y2 / r)\n",
        "\n",
        "    boxes.append((0, conf, x1, y1, x2, y2))\n",
        "  return boxes\n",
        "\n",
        "\n",
        "# Inference\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "with open(ENGINE_PATH, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
        "  engine = runtime.deserialize_cuda_engine(f.read())\n",
        "  context = engine.create_execution_context()\n",
        "\n",
        "  input_idx = engine.get_binding_index(engine[0])\n",
        "  output_idx = engine.get_binding_index(engine[1])\n",
        "  context.set_binding_shape(input_idx, (1, 3, INPUT_H, INPUT_W))\n",
        "\n",
        "  input_size = trt.volume(context.get_binding_shape(input_idx))\n",
        "  output_size = trt.volume(context.get_binding_shape(output_idx))\n",
        "  input_np = np.empty(input_size, dtype=np.float32)\n",
        "  output_np = np.empty(output_size, dtype=np.float32)\n",
        "\n",
        "  input_ptr = input_np.ctypes.data\n",
        "  output_ptr = output_np.ctypes.data\n",
        "\n",
        "  bindings = [int(input_ptr), int(output_ptr)]\n",
        "\n",
        "  image_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*.jpg\")))\n",
        "  total_time = 0.0\n",
        "\n",
        "  for img_path in image_paths:\n",
        "    img_input, img_orig, orig_shape, r, top, left = preprocess(img_path)\n",
        "    np.copyto(input_np, img_input.ravel())\n",
        "\n",
        "    start = time.time()\n",
        "    context.execute_v2(bindings)\n",
        "    end = time.time()\n",
        "\n",
        "    pred = output_np.copy()\n",
        "    detections = postprocess(pred, orig_shape, r, top, left)\n",
        "\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    out_txt = os.path.join(OUT_TXT_DIR, base + \".txt\")\n",
        "    out_img = os.path.join(OUT_IMG_DIR, base + \".jpg\")\n",
        "\n",
        "    with open(out_txt, \"w\") as f:\n",
        "      for cls, conf, x1, y1, x2, y2 in detections:\n",
        "        f.write(f\"{cls} {conf:.4f} {x1} {y1} {x2} {y2}\\n\")\n",
        "        cv2.rectangle(img_orig, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        cv2.putText(img_orig, f\"{conf:.2f}\", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
        "\n",
        "    cv2.imwrite(out_img, img_orig)\n",
        "    total_time += (end - start)\n",
        "    print(f\"[{base}] done in {end - start:.3f}s\")\n",
        "\n",
        "  avg = total_time / len(image_paths)\n",
        "  print(f\"Done. Avg latency: {avg:.3f}s | FPS: {1/avg:.2f}\")\n",
        "\n",
        "  throughput = len(image_paths) / total_time\n",
        "  print(f\"Throughput: {throughput:.2f} img/s\")\n",
        "\n",
        "  with open(\"results/metrics_summary.txt\", \"w\") as f:\n",
        "    f.write(\"Model: YOLOv8n\\\\n\")\n",
        "    f.write(f\"Total images: {len(image_paths)}\\\\n\")\n",
        "    f.write(f\"Total time: {total_time:.3f} sec\\\\n\")\n",
        "    f.write(f\"Avg latency: {avg:.3f} sec\\\\n\")\n",
        "    f.write(f\"FPS: {1/avg:.2f}\\\\n\")\n",
        "    f.write(f\"Throughput: {throughput:.2f} img/sec\\\\n\")"
      ],
      "metadata": {
        "id": "2YHxvM2GD8h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script senza pyCUDA:"
      ],
      "metadata": {
        "id": "1HVwT5rGD8PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "\n",
        "# CONFIG\n",
        "ONNX_PATH = \"best_yolov8n.onnx\"\n",
        "IMG_DIR = \"test/images\"\n",
        "OUT_IMG_DIR = \"results_onnx/inference_annotated\"\n",
        "OUT_TXT_DIR = \"results_onnx/inference_txt\"\n",
        "METRICS_FILE = \"results_onnx/metrics_summary.txt\"\n",
        "CONF_THRESH = 0.25\n",
        "INPUT_H, INPUT_W = 640, 640\n",
        "\n",
        "os.makedirs(OUT_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_TXT_DIR, exist_ok=True)\n",
        "os.makedirs(\"results_onnx\", exist_ok=True)\n",
        "\n",
        "# PREPROCESSING\n",
        "def preprocess(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  orig = img.copy()\n",
        "  h0, w0 = img.shape[:2]\n",
        "\n",
        "  r = min(INPUT_W / w0, INPUT_H / h0)\n",
        "  new_w, new_h = int(w0 * r), int(h0 * r)\n",
        "  resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  canvas = np.full((INPUT_H, INPUT_W, 3), 114, dtype=np.uint8)\n",
        "  top = (INPUT_H - new_h) // 2\n",
        "  left = (INPUT_W - new_w) // 2\n",
        "  canvas[top:top + new_h, left:left + new_w] = resized\n",
        "\n",
        "  img_rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
        "  img_norm = img_rgb.astype(np.float32) / 255.0\n",
        "  img_trans = np.transpose(img_norm, (2, 0, 1))\n",
        "  img_final = np.expand_dims(img_trans, axis=0)\n",
        "\n",
        "  return img_final.astype(np.float32), orig, (h0, w0), r, top, left\n",
        "\n",
        "# POSTPROCESSING\n",
        "def postprocess(output, orig_shape, r, top, left):\n",
        "  h0, w0 = orig_shape\n",
        "  output = output.reshape(5, -1)\n",
        "  boxes = []\n",
        "  for i in range(output.shape[1]):\n",
        "    x, y, w, h, conf = output[:, i]\n",
        "    if conf < CONF_THRESH:\n",
        "      continue\n",
        "    x1 = int((x - w / 2) - left)\n",
        "    y1 = int((y - h / 2) - top)\n",
        "    x2 = int((x + w / 2) - left)\n",
        "    y2 = int((y + h / 2) - top)\n",
        "    x1 = int(x1 / r)\n",
        "    x2 = int(x2 / r)\n",
        "    y1 = int(y1 / r)\n",
        "    y2 = int(y2 / r)\n",
        "    boxes.append((0, conf, x1, y1, x2, y2))\n",
        "  return boxes\n",
        "\n",
        "# INFERENZA\n",
        "session = ort.InferenceSession(ONNX_PATH, providers=['CPUExecutionProvider']) # only CPU\n",
        "# It only works if Jetson Nano has ONNX Runtime installed with CUDA support, which is often not available by default\n",
        "# session = ort.InferenceSession(ONNX_PATH, providers=['CUDAExecutionProvider', 'CPUExecutionProvider']) # with GPU\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "image_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*.jpg\")))\n",
        "total_time = 0.0\n",
        "\n",
        "for img_path in image_paths:\n",
        "  img_input, img_orig, orig_shape, r, top, left = preprocess(img_path)\n",
        "\n",
        "  start = time.time()\n",
        "  preds = session.run([output_name], {input_name: img_input})[0]\n",
        "  end = time.time()\n",
        "\n",
        "  detections = postprocess(preds, orig_shape, r, top, left)\n",
        "\n",
        "  base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "  out_txt = os.path.join(OUT_TXT_DIR, base + \".txt\")\n",
        "  out_img = os.path.join(OUT_IMG_DIR, base + \".jpg\")\n",
        "\n",
        "  with open(out_txt, \"w\") as f:\n",
        "    for cls, conf, x1, y1, x2, y2 in detections:\n",
        "      f.write(f\"{cls} {conf:.4f} {x1} {y1} {x2} {y2}\\n\")\n",
        "      cv2.rectangle(img_orig, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "      cv2.putText(img_orig, f\"{conf:.2f}\", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
        "\n",
        "  cv2.imwrite(out_img, img_orig)\n",
        "  total_time += (end - start)\n",
        "  print(f\"[{base}] done in {end - start:.3f}s\")\n",
        "\n",
        "# METRICS\n",
        "avg = total_time / len(image_paths)\n",
        "throughput = len(image_paths) / total_time\n",
        "print(f\"Done. Avg latency: {avg:.3f}s | FPS: {1/avg:.2f} | Throughput: {throughput:.2f} img/s\")\n",
        "\n",
        "with open(METRICS_FILE, \"w\") as f:\n",
        "  f.write(\"Model: YOLOv8n (ONNX Runtime)\\\\n\")\n",
        "  f.write(f\"Total images: {len(image_paths)}\\\\n\")\n",
        "  f.write(f\"Total time: {total_time:.3f} sec\\\\n\")\n",
        "  f.write(f\"Avg latency: {avg:.3f} sec\\\\n\")\n",
        "  f.write(f\"FPS: {1/avg:.2f}\\\\n\")\n",
        "  f.write(f\"Throughput: {throughput:.2f} img/sec\\\\n\")"
      ],
      "metadata": {
        "id": "EJwjyxMXSmkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "\n",
        "ENGINE_PATH = \"best_yolov8n.engine\"\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "\n",
        "# Model loading and output analysis\n",
        "with open(ENGINE_PATH, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
        "  engine = runtime.deserialize_cuda_engine(f.read())\n",
        "  context = engine.create_execution_context()\n",
        "\n",
        "  print(f\"Numero di binding: {engine.num_bindings}\")\n",
        "  for i in range(engine.num_bindings):\n",
        "    name = engine.get_binding_name(i)\n",
        "    shape = engine.get_binding_shape(i)\n",
        "    dtype = engine.get_binding_dtype(i)\n",
        "    io = \"Input\" if engine.binding_is_input(i) else \"Output\"\n",
        "    print(f\"[{io}] {name} - shape: {shape}, dtype: {dtype}\")"
      ],
      "metadata": {
        "id": "9poVjndS8BeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cP84Fi0286Ti"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}